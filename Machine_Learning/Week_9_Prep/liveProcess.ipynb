{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1585fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import medfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60b2dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_FREQ = 20 # Hz \n",
    "WINDOW_SIZE = 2 # sec \n",
    "OVERLAP = 20 \n",
    "SEGMENT_SIZE = SAMPLING_FREQ * WINDOW_SIZE # 40\n",
    "\n",
    "SENSOR_COLS = [\"acc_X\", \"acc_Y\", \"acc_Z\", \"gyro_X\", \"gyro_Y\", \"gyro_Z\", \"yaw\", \"pitch\", \"roll\"]\n",
    "\n",
    "TRAIN_MAX = {'acc_X': 1.27,\n",
    "             'acc_Y': 1.27,\n",
    "             'acc_Z': 1.27,\n",
    "             'gyro_X': 276.28,\n",
    "             'gyro_Y': 266.44,\n",
    "             'gyro_Z': 271.8,\n",
    "             'yaw': 327.28,\n",
    "             'pitch': 15.59,\n",
    "             'roll': 15.14\n",
    "            }\n",
    "\n",
    "\n",
    "CUMULATIVE_DATA = np.zeros((1,len(SENSOR_COLS)), dtype=float, order='C') # holds rows of live sensor data sent \n",
    "CUMULATIVE_DATA = np.delete(CUMULATIVE_DATA, 0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f40bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(df):\n",
    "    \"\"\"\n",
    "    Applies 3rd order median filter for each signal i.e. Each axial column in dataset.\n",
    "    Input: raw_df\n",
    "    \"\"\"\n",
    "    \n",
    "    global SENSOR_COLS\n",
    "    \n",
    "    for col in SENSOR_COLS: \n",
    "        array = np.array(df[col]) \n",
    "        med_filtered = medfilt(array, kernel_size=3) \n",
    "        df[col] = med_filtered  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2236d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliseData(dframe):\n",
    "    \"\"\"\n",
    "    Normalize features for data (values between -1 and 1). Columns rounded to 4dp after normalisation.\n",
    "    Input: raw sensor dframe \n",
    "    \"\"\"\n",
    "    \n",
    "    global SENSOR_COLS, TRAIN_MAX\n",
    "    \n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    for col in SENSOR_COLS:\n",
    "        dframe[col] = dframe[col].div(100).round(6)\n",
    "        dframe[col] = dframe[col] / TRAIN_MAX[col]\n",
    "        dframe[col] = dframe[col].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "598b3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentator():\n",
    "    \"\"\"\n",
    "    Extract segments using fixed-width sliding windows of size 2s. \n",
    "    Return: 3D Numpy array of size : n segments * 40 rows * 9 axial cols\n",
    "    \"\"\"\n",
    "    global CUMULATIVE_DATA, OVERLAP, SEGMENT_SIZE,SENSOR_COLS\n",
    "    \n",
    "    # loop through the 2d array of nrows * 9\n",
    "    # capture each column ==> len of each col = 40 and there should 9 cols ==> this will be the first segment \n",
    "    # segments will be a n segments * 9 col * 40 values \n",
    "    \n",
    "    segments = []\n",
    "    for row in range(0, len(CUMULATIVE_DATA)-(SEGMENT_SIZE-1), OVERLAP): \n",
    "        print(f\"Sampling row : {row} to row : {row+SEGMENT_SIZE}\")\n",
    "        windows = []\n",
    "        for col in range(0,len(SENSOR_COLS)):\n",
    "            windows.append(CUMULATIVE_DATA[row:row+SEGMENT_SIZE,col])\n",
    "        print(\"Shape of Window: \", np.asarray(windows).shape)\n",
    "        segments.append(windows)\n",
    "    print(\"Shape of segments : \", np.asarray(segments).shape)\n",
    "    CUMULATIVE_DATA = np.delete(CUMULATIVE_DATA, np.s_[0:OVERLAP], axis = 0) \n",
    "    reshaped_segments = np.asarray(segments,dtype =np.float32).reshape(-1,SEGMENT_SIZE,len(SENSOR_COLS))\n",
    "    return reshaped_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da297191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfinalSegs(segs):\n",
    "    \"\"\"\n",
    "    Filter and Normalise each window selected.\n",
    "    Input: 3D Numpy segments array obtained after segmentation\n",
    "    Return: 3D Numpy array upon filtering & normalisation\n",
    "    \"\"\"\n",
    "    arr = np.asarray(segs)\n",
    "    final_segs = []\n",
    "    for r in range(0, arr.shape[0]):\n",
    "        df = pd.DataFrame(arr[r], index=None, columns=SENSOR_COLS)\n",
    "        filter_signal(df)\n",
    "        normaliseData(df)\n",
    "        final_segs.append(df.values)\n",
    "    return np.asarray(final_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63dbef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputVector(finalSegs):\n",
    "    \"\"\"\n",
    "    Get the input vector to be fed into nn.\n",
    "    Input: finalSegs after filtering and normalisation \n",
    "    Return: Input vector of shape n windows * (20*2*12)\n",
    "    \"\"\"\n",
    "    global SAMPLING_FREQ, WINDOW_SIZE, SENSOR_COLS\n",
    "    \n",
    "    num_of_input_features = SAMPLING_FREQ * WINDOW_SIZE * len(SENSOR_COLS)\n",
    "    inputVector = finalSegs.reshape(finalSegs.shape[0], num_of_input_features)\n",
    "    \n",
    "    return inputVector.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e85e2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append(data):\n",
    "    \"\"\"\n",
    "    Each row of live sensor data of 9 axial values, will be appended to a global 2D Numpy array. \n",
    "    From the global 2D Numpy array, a window of readings will be selected \n",
    "    to form an input vector of shape n x 360 to be fed into the nn.\n",
    "    Input: data, i.e. 2D Numpy array of shape (40,6) is preferred \n",
    "    Returns: n x (40 * 9) Numpy array to be fed as input to nn model, where n is the number of windows\n",
    "    \"\"\"\n",
    "    global CUMULATIVE_DATA , SEGMENT_SIZE, SENSOR_COLS\n",
    "    arr = np.array(data)\n",
    "    \n",
    "    # padding \n",
    "    if len(arr) < SEGMENT_SIZE:\n",
    "        leftover = SEGMENT_SIZE - len(arr)\n",
    "        padding = np.zeros((leftover, len(SENSOR_COLS) ),dtype=float, order='C')\n",
    "        arr = np.concatenate((arr,padding))\n",
    "        \n",
    "    CUMULATIVE_DATA = np.concatenate((CUMULATIVE_DATA, arr))\n",
    "#     print(\"GLOBAL ARRAY SHAPE BEFORE SEGMENTATION : \", CUMULATIVE_DATA.shape)\n",
    "    segs = segmentator()\n",
    "#     print(\"GLOBAL ARRAY SHAPE AFTER SEGMENTATION : \", CUMULATIVE_DATA.shape)\n",
    "    fin_segs = getfinalSegs(segs)\n",
    "    iv = getInputVector(fin_segs)\n",
    "    \n",
    "    return iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d26c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetCumData():\n",
    "    \"\"\"\n",
    "    Function to be called before the start of dance move execution. Resets CUMULATIVE_DATA to empty numpy arr. \n",
    "    \"\"\"\n",
    "    global CUMULATIVE_DATA, SENSOR_COLS\n",
    "    \n",
    "    # holds rows of sensor data with 9 axial cols\n",
    "    CUMULATIVE_DATA = np.zeros((1,len(SENSOR_COLS)), dtype=float, order='C')  \n",
    "    CUMULATIVE_DATA = np.delete(CUMULATIVE_DATA, 0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad073d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for testing \n",
    "# resetCumData()\n",
    "# df = pd.read_csv(\"./capstone_data/test/dab_sean_1.csv\", index_col=None, header = None )\n",
    "# iv = append(np.asarray(df.values[0:20, 0:9]))\n",
    "# print(\"input vector shape:\", iv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7dd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv = append(np.asarray(df.values[20:40, 0:9]))\n",
    "# print(\"input vector shape:\", iv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "663c61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv = append(np.asarray(df.values[40:60, 0:9]))\n",
    "# print(\"input vector shape:\", iv.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
