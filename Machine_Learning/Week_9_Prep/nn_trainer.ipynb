{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import medfilt\n",
    "from scipy.fftpack import fft \n",
    "from scipy.fftpack import fftfreq \n",
    "from scipy.fftpack import ifft \n",
    "from numpy.fft import *\n",
    "from scipy import fftpack\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split,SubsetRandomSampler, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "from statistics import mean, stdev\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sn\n",
    "plt.style.use('ggplot')\n",
    "sn.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209383b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7g/s2wk6v_57ln9rzfc5thbvk880000gn/T/ipykernel_21267/3425120541.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUT_FEATURES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, h1, h2, out_features=OUT_FEATURES):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
    "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
    "        self.out = nn.Linear(h2, out_features)  # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Instantiate the Model class using parameter defaults:\n",
    "torch.manual_seed(32)\n",
    "hidden_layer_1_nodes = 80\n",
    "hidden_layer_2_nodes = 40\n",
    "mlp = Model(in_features=training_X.shape[1], h1=hidden_layer_1_nodes, h2=hidden_layer_2_nodes)\n",
    "X_train = torch.FloatTensor(training_X)\n",
    "X_test = torch.FloatTensor(testing_X)\n",
    "y_train = torch.LongTensor(lbl_train)\n",
    "y_test = torch.LongTensor(lbl_test)\n",
    "# trainloader = DataLoader(X_train, batch_size=60, shuffle=True)\n",
    "# testloader = DataLoader(X_test, batch_size=60, shuffle=False)\n",
    "# len(X_important_train[0])\n",
    "\n",
    "\n",
    "k = 10       \n",
    "skfcv = StratifiedKFold(n_splits=k, shuffle=True, random_state=1)\n",
    "epochs = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.01)\n",
    "training_loss = {}\n",
    "train_batch_size = 108\n",
    "test_batch_size = 72\n",
    "val_acc = []\n",
    "# per fold \n",
    "for fold, (train_index, test_index) in enumerate(skfcv.split(X_train, y_train)):\n",
    "    x_train_fold, x_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "    train_combined = TensorDataset(x_train_fold, y_train_fold)\n",
    "    test_combined = TensorDataset(x_test_fold, y_test_fold)\n",
    "    trainloader = DataLoader(train_combined, batch_size=train_batch_size, shuffle=True)\n",
    "    testloader = DataLoader(test_combined, batch_size=test_batch_size, shuffle=False)\n",
    "    # per epoch\n",
    "    for i in range(epochs): \n",
    "        i+=1\n",
    "        # per batch \n",
    "        losses = [] \n",
    "        val_correct_preds = 0\n",
    "        count = 0 \n",
    "        for batch_idx, (data, target) in enumerate(trainloader):\n",
    "            mlp.train()\n",
    "             \n",
    "            # training \n",
    "            y_pred = mlp.forward(data)\n",
    "            loss = criterion(y_pred, target)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # backtracking \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "        \n",
    "        # validating \n",
    "        with torch.no_grad():\n",
    "            mlp.eval()\n",
    "            for val_batch_idx, (val_data, val_target) in enumerate(testloader):\n",
    "                y_out = mlp.forward(val_data)\n",
    "#                 print(y_out.shape[0])\n",
    "                for row in range(y_out.shape[0]):\n",
    "#                     print(\"predicted:\" , y_out[row].argmax())\n",
    "#                     print(\"actual: \", val_target[row])\n",
    "                    if y_out[row].argmax() == val_target[row]:\n",
    "                        val_correct_preds += 1\n",
    "                    count += 1\n",
    "\n",
    "            \n",
    "    # per fold         \n",
    "    with torch.no_grad():\n",
    "        training_loss[fold] = np.array(losses).mean()\n",
    "        print(\"-----------------------\")\n",
    "        print(f\"fold: {fold} , training_loss: {training_loss[fold]}\")\n",
    "        print(f\"fold: {fold}, {val_correct_preds} out of {count} = {100*val_correct_preds/count:.2f}% correct\")\n",
    "        print(\"-----------------------\")\n",
    "        val_acc.append(100*val_correct_preds/count)\n",
    "        count = 0\n",
    "\n",
    "print()\n",
    "print(\"Done Training\")\n",
    "print(\"Max Validation Accuracy: \",  np.array(val_acc).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b883d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    y_val = mlp.forward(X_test)\n",
    "    print(\"--- %s execution time in seconds ---\" % (time.time() - start_time))\n",
    "    loss = criterion(y_val, y_test)\n",
    "    print(f'Loss with test set : {loss:.8f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
