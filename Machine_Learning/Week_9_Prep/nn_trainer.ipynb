{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9186abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training segments shape:  (5398, 20, 12)\n",
      "Testing segments shape:  (1078, 20, 12)\n",
      "Input Training Vector shape:  (5398, 240)\n",
      "Input Testing Vector shape:  (1078, 240)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from statistics import mean\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "plt.style.use('ggplot')\n",
    "sn.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from features import normaliseTrainData,normaliseTestData, time_domain_feature_gen, gen_rawData \n",
    "from features import load_data_paths, getInputVector, segment_df, concatenator, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ecae0",
   "metadata": {},
   "source": [
    "## Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861f0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILEPATH = \"./capstone_data/train/*.csv\"\n",
    "TEST_FILEPATH = \"./capstone_data/test/*.csv\"\n",
    "\n",
    "DANCE_TO_NUM_MAP = {'dab': 0, 'jamesbond': 1, 'mermaid': 2}\n",
    "RAW_COLS = [\"acc_X\", \"acc_Y\", \"acc_Z\", \"gyro_X\", \"gyro_Y\", \"gyro_Z\",\"subject\", \"trialNum\", \"dance\"]\n",
    "\n",
    "DANCE_MOVES = [\"jamesbond\", \"dab\", \"mermaid\"]\n",
    "IN_FEATURES = 240\n",
    "OUT_FEATURES = 3\n",
    "HIDDEN_LAYER_1_NODES = 100\n",
    "HIDDEN_LAYER_2_NODES = 60\n",
    "K = 10   \n",
    "EPOCHS = 100\n",
    "TRAIN_BATCH_SIZE = 108\n",
    "TEST_BATCH_SIZE = 72\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_TO_DANCE_MAP = {0: 'dab', 1: 'jamesbond', 2: 'mermaid'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c02a4",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d637cb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training segments shape:  (5398, 20, 12)\n",
      "Testing segments shape:  (1078, 20, 12)\n",
      "Input Training Vector shape:  (5398, 240)\n",
      "Input Testing Vector shape:  (1078, 240)\n"
     ]
    }
   ],
   "source": [
    "# # test\n",
    "# test_dic = generate_final_dataset(gen_rawData(load_data_paths(TEST_FILEPATH)))\n",
    "# data_test, lbl_test = segment_df(concatenator(test_dic), \"target\")\n",
    "# testing_X = getInputVector(data_test)\n",
    "# print(f\"testing_X input vector shape : {testing_X.shape}\")\n",
    "# print(f\"labels for test shape: {lbl_test.shape}\")\n",
    "\n",
    "# # train\n",
    "# train_dic = generate_final_dataset(gen_rawData(load_data_paths(TRAIN_FILEPATH)))\n",
    "# data_train, lbl_train = segment_df(concatenator(train_dic), \"target\")\n",
    "# training_X = getInputVector(data_train)\n",
    "# print(f\"training_X input vector shape : {training_X.shape}\")\n",
    "# print(f\"labels for train shape: {lbl_train.shape}\")\n",
    "\n",
    "# testing\n",
    "\n",
    "raw_test_df = concatenator(gen_rawData(load_data_paths(TEST_FILEPATH)))\n",
    "raw_train_df = concatenator(gen_rawData(load_data_paths(TRAIN_FILEPATH)))\n",
    "train_max = normaliseTrainData(raw_train_df)\n",
    "normaliseTestData(raw_test_df, train_max)\n",
    "feature_test_df = time_domain_feature_gen(raw_test_df)\n",
    "feature_train_df = time_domain_feature_gen(raw_train_df)\n",
    "feature_train_df[\"target\"] = feature_train_df[\"dance\"].map(DANCE_TO_NUM_MAP)\n",
    "feature_test_df = time_domain_feature_gen(raw_test_df)\n",
    "feature_test_df[\"target\"] = feature_test_df[\"dance\"].map(DANCE_TO_NUM_MAP)\n",
    "segment_train_df = feature_train_df.drop(RAW_COLS, axis = 1)\n",
    "segment_test_df = feature_test_df.drop(RAW_COLS, axis=1)\n",
    "train_segs, lbl_train = segment_df(segment_train_df,\"target\")\n",
    "test_segs, lbl_test = segment_df(segment_test_df, \"target\")\n",
    "training_X = getInputVector(train_segs)\n",
    "testing_X = getInputVector(test_segs)\n",
    "print(\"Training segments shape: \", train_segs.shape)\n",
    "print(\"Testing segments shape: \", test_segs.shape)\n",
    "print(\"Input Training Vector shape: \", training_X.shape)\n",
    "print(\"Input Testing Vector shape: \", testing_X.shape)\n",
    "\n",
    "X_train = torch.FloatTensor(training_X)\n",
    "X_test = torch.FloatTensor(testing_X)\n",
    "y_train = torch.LongTensor(lbl_train)\n",
    "y_test = torch.LongTensor(lbl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3431321",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209383b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, h1, h2, out_features):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
    "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
    "        self.out = nn.Linear(h2, out_features)  # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc28a4c",
   "metadata": {},
   "source": [
    "#### Instantiate Model class using default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed47fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(32)\n",
    "mlp = Model(in_features=IN_FEATURES, h1=HIDDEN_LAYER_1_NODES, h2=HIDDEN_LAYER_2_NODES, out_features=OUT_FEATURES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430acd4d",
   "metadata": {},
   "source": [
    "#### 10-fold Stratified Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ded229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "fold: 0 , training_loss: 3.972444062583236e-07\n",
      "fold: 0, 532 out of 540 = 98.52% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 1 , training_loss: 1.7308796032011742e-06\n",
      "fold: 1, 538 out of 540 = 99.63% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 2 , training_loss: 4.751834239868913e-06\n",
      "fold: 2, 535 out of 540 = 99.07% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 3 , training_loss: 2.669352397788316e-05\n",
      "fold: 3, 539 out of 540 = 99.81% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 4 , training_loss: 3.016773007402662e-06\n",
      "fold: 4, 540 out of 540 = 100.00% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 5 , training_loss: 9.74860267888289e-06\n",
      "fold: 5, 538 out of 540 = 99.63% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 6 , training_loss: 6.960767495911568e-05\n",
      "fold: 6, 535 out of 540 = 99.07% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 7 , training_loss: 7.962796189531218e-06\n",
      "fold: 7, 537 out of 540 = 99.44% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 8 , training_loss: 1.544646147522144e-05\n",
      "fold: 8, 539 out of 539 = 100.00% correct\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "skfcv = StratifiedKFold(n_splits=K, shuffle=True, random_state=1)\n",
    "training_loss = {}\n",
    "val_acc = []\n",
    "\n",
    "# per fold \n",
    "for fold, (train_index, test_index) in enumerate(skfcv.split(X_train, y_train)):\n",
    "    x_train_fold, x_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "    train_combined = TensorDataset(x_train_fold, y_train_fold)\n",
    "    test_combined = TensorDataset(x_test_fold, y_test_fold)\n",
    "    trainloader = DataLoader(train_combined, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "    testloader = DataLoader(test_combined, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "    # per epoch\n",
    "    for i in range(EPOCHS): \n",
    "        i+=1\n",
    "        # per batch \n",
    "        losses = [] \n",
    "        val_correct_preds = 0\n",
    "        count = 0 \n",
    "        for batch_idx, (data, target) in enumerate(trainloader):\n",
    "            mlp.train()\n",
    "             \n",
    "            # training \n",
    "            y_pred = mlp.forward(data)\n",
    "            loss = criterion(y_pred, target)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # backtracking \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "        \n",
    "        # validating \n",
    "        with torch.no_grad():\n",
    "            mlp.eval()\n",
    "            for val_batch_idx, (val_data, val_target) in enumerate(testloader):\n",
    "                y_out = mlp.forward(val_data)\n",
    "                for row in range(y_out.shape[0]):\n",
    "                    if y_out[row].argmax() == val_target[row]:\n",
    "                        val_correct_preds += 1\n",
    "                    count += 1\n",
    "                    \n",
    "    # per fold         \n",
    "    with torch.no_grad():\n",
    "        training_loss[fold] = np.array(losses).mean()\n",
    "        print(\"-----------------------\")\n",
    "        print(f\"fold: {fold} , training_loss: {training_loss[fold]}\")\n",
    "        print(f\"fold: {fold}, {val_correct_preds} out of {count} = {100*val_correct_preds/count:.2f}% correct\")\n",
    "        print(\"-----------------------\")\n",
    "        val_acc.append(100*val_correct_preds/count)\n",
    "        count = 0\n",
    "\n",
    "print()\n",
    "print(\"Done Training\")\n",
    "print(\"Max Validation Accuracy: \",  np.array(val_acc).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b52e3",
   "metadata": {},
   "source": [
    "#### Mean Loss per fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf240080",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_axis  = training_loss.values()\n",
    "    plt.plot(range(10), y_axis)\n",
    "    plt.ylabel('Mean Loss per fold')\n",
    "    plt.xlabel('Folds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc32f7",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b883d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    y_val = mlp.forward(X_test)\n",
    "    print(\"--- %s execution time in seconds ---\" % (time.time() - start_time))\n",
    "    loss = criterion(y_val, y_test)\n",
    "    print(f'Loss with test set : {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # checking accuracy on test dataset \n",
    "    preds = []\n",
    "    correct = 0\n",
    "    for i,data in enumerate(X_test):\n",
    "        y_val = mlp.forward(data)\n",
    "        preds.append(y_val.argmax().item())\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "    print(f'\\n{correct} out of {len(y_test)} = {100*correct/len(y_test):.2f}% correct')\n",
    "    y_preds = torch.tensor(preds, dtype = torch.int64)\n",
    "    stacked = torch.stack((y_test,y_preds),dim=1)\n",
    "\n",
    "    # confusion matrix generation \n",
    "    cmt = torch.zeros(OUT_FEATURES,OUT_FEATURES, dtype=torch.int64)\n",
    "    for p in stacked:\n",
    "        tl, pl = p.tolist()\n",
    "        cmt[tl, pl] = cmt[tl, pl] + 1  \n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    plot_confusion_matrix(cmt, DANCE_MOVES)\n",
    "    \n",
    "    print(\"Classification Report for MLP :\")\n",
    "    print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4da898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model weights \n",
    "with torch.no_grad():\n",
    "    mlp_params = {}\n",
    "    for name, param in mlp.named_parameters():\n",
    "        mlp_params[name] = param.numpy().copy().tolist()\n",
    "        \n",
    "    print(mlp_params.keys())\n",
    "    for key in mlp_params.keys(): \n",
    "        print(f\"{key} : {len(mlp_params[key])} neurons in {key} layer\")\n",
    "        print(f\" number of connections  : {len(mlp_params[key])} * {np.asarray(mlp_params[key][len(mlp_params[key]) -1]).size} = {len(mlp_params[key]) * np.asarray(mlp_params[key][len(mlp_params[key]) -1]).size } \")\n",
    "\n",
    "    # save model weights \n",
    "    with open('mlp.csv', 'w') as csv_file:  \n",
    "        writer = csv.writer(csv_file)\n",
    "        for key, value in mlp_params.items():\n",
    "           writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940b253",
   "metadata": {},
   "source": [
    "## Save & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d3de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlp.state_dict(), 'MLPW9.pt')\n",
    "loaded_model = Model(in_features=IN_FEATURES,h1=HIDDEN_LAYER_1_NODES, h2=HIDDEN_LAYER_2_NODES, out_features=OUT_FEATURES) \n",
    "loaded_model.load_state_dict(torch.load('MLPW9.pt'))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss when loaded model is run on test dataset \n",
    "with torch.no_grad():\n",
    "    y_val = loaded_model.forward(X_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "    print(f'{loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model on a random sample row of the test dataset \n",
    "random.seed(69)\n",
    "random_int = random.randint(0, len(testing_X))\n",
    "random_input = torch.FloatTensor(testing_X[random_int])\n",
    "print(random_input)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(loaded_model(random_input))\n",
    "    print()\n",
    "    print(loaded_model(random_input).max())\n",
    "    print(loaded_model(random_input).argmax().item())\n",
    "    print(f\"Predicted Output: {NUM_TO_DANCE_MAP[loaded_model(random_input).argmax().item()]}\")\n",
    "    print(f\"Actual Output: {NUM_TO_DANCE_MAP[y_test[random_int].item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test dataset\n",
    "with torch.no_grad(): \n",
    "    x = X_test.numpy().copy().tolist()\n",
    "    np.savetxt(\"X_test.csv\", x, delimiter=\",\")\n",
    "    y = y_test.numpy().copy().tolist()\n",
    "    np.savetxt(\"y_test.csv\", y, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fdb054",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
