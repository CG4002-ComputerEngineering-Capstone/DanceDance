{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b138879f",
   "metadata": {},
   "source": [
    "### Discrete Stochastic Signal Analysis\n",
    "\n",
    "#### Theory\n",
    "- Time series data: y = f(t)\n",
    "- Signal is more general. The independent variable can be t, spatial coordinates, frequency, etc.\n",
    "    - For e.g. a picture can be seen as a signal which contains information about the brightness of three colors (RGB) across two spatial dimensions.\n",
    "- The Nyquist rate is twice the highest frequency present in the signal.\n",
    "- A signal is said to be under-sampled if the sampling rate is smaller than the Nyquist rate. \n",
    "- Human activity frequencies are between 0 and 20 Hz, and 98% of the FFT amplitude is contained below 10 Hz.\n",
    "\n",
    "> Any signal can be decomposed into a sum of its simpler signals. These simpler signals are trigonometric functions (sine and cosine waves). \n",
    "\n",
    "FFT : time-domain to frequency-domain. \n",
    "\n",
    "### Signal processing pipeline \n",
    "> Meaurements are done at a constant rate of `20Hz`. After filtering out the noise, the signals are segmented in fixed-width windows of `2 sec` with an overlap of `1 sec`. Each window will therefore have `20 x 2 = 40 samples` in total.\n",
    "\n",
    "> Each window is a row of the input vector. Just by looking at 3-axial acc and 3-axial gyro readings for each sample point in a window, each window would contain `6 * 40 = 240 cols `\n",
    "\n",
    "#### If t_signal is an acceleration signal: \n",
    "- t_DC_component is the gravity component [Grav_acc]\n",
    "- t_body_component is the body's acceleration component [Body_acc]\n",
    "\n",
    "#### If t_signal is a gyro signal:  \n",
    "- t_DC_component is not useful [noise]\n",
    "- t_body_component is the body's angular velocity component [Body_gyro]\n",
    "\n",
    "#### f_signals: \n",
    "- DC_component: f_signal values having freq between `[-0.3 hz to 0 hz]` and from `[0 hz to 0.3hz]`\n",
    "- body_component: f_signal values having freq between` [-10 hz to -0.3 hz)` and from `(0.3 hz to 10 hz] `\n",
    "\n",
    "\n",
    "#### References: \n",
    "- https://en.wikipedia.org/wiki/Median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f538a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import medfilt\n",
    "from scipy.fftpack import fft \n",
    "from scipy.fftpack import fftfreq \n",
    "from scipy.fftpack import ifft \n",
    "from numpy.fft import *\n",
    "from scipy import fftpack\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split,SubsetRandomSampler, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "from statistics import mean, stdev\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sn\n",
    "plt.style.use('ggplot')\n",
    "sn.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02469d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_FREQ = 20\n",
    "WINDOW_SIZE = 2\n",
    "OVERLAP = 50\n",
    "NYQ = SAMPLING_FREQ / float(2) # Nyquist frequency \n",
    "CUTOFF = 0.3 \n",
    "MAXFREQ = 10 \n",
    "OUT_FEATURES = 3\n",
    "DANCE_MOVES = [\"jamesbond\", \"dab\", \"mermaid\"]\n",
    "TRAIN_SUBJECTS = ['chekjun','haritha', 'matthew' ,'nishanth', 'priyan']\n",
    "SENSOR_COLS = [\"acc_X\", \"acc_Y\", \"acc_Z\", \"gyro_X\", \"gyro_Y\", \"gyro_Z\", \"yaw\", \"pitch\", \"roll\"]\n",
    "DANCE_TO_NUM_MAP = {'dab': 0, 'jamesbond': 1, 'mermaid': 2}\n",
    "NUM_TO_DANCE_MAP = {0: 'dab', 1: 'jamesbond', 2: 'mermaid'}\n",
    "TRAIN_FILEPATH = \"./capstone_data/train/*.csv\"\n",
    "TEST_FILEPATH = \"./capstone_data/test/*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8692f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_paths(location):\n",
    "    \"\"\"\n",
    "    Gets file path to each csv data file \n",
    "    Input: filepath to csv files \n",
    "    Returns: array of filepath to each csv which contains sensor data for each trial by a subject for a dance move \n",
    "    \"\"\"\n",
    "    data_paths = []\n",
    "    for name in glob.glob(location):\n",
    "        data_paths.append(name)\n",
    "    return data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cf9524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(signal):\n",
    "    \"\"\"\n",
    "    Applies 3rd order median filter for each signal i.e. Each axial column in dataset\n",
    "    Input: numpy array 1D (one column)\n",
    "    Returns: 3rd order median-filtered signal - numpy array 1D\n",
    "    \"\"\"\n",
    "    array = np.array(signal)   \n",
    "    med_filtered = medfilt(array, kernel_size=3) \n",
    "    return  med_filtered  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79041ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_3_signals(x,y,z): \n",
    "    \"\"\"\n",
    "    Finding Euclidian magnitude of 3-axial signal \n",
    "    Inputs: x, y , z columns (numpy arrays)\n",
    "    Returns: Euclidian magnitude of each row \n",
    "    \"\"\"\n",
    "    return [math.sqrt((x[i]**2+y[i]**2+z[i]**2)) for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f6d6e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_domain_feature_per_signal(t_signal,cutoff,maxfreq,sampling_freq):\n",
    "    \"\"\"\n",
    "    For each time-domain signal, i.e. accx,y,z and gyrox,y,z, get their respective time-domain components \n",
    "    Inputs: t_signal i.e. 1D numpy array (time domain signal), cutoff_freq, maxfreq, sampling_freq\n",
    "    Returns: (total_component, t_DC_component , t_body_component, t_noise)\n",
    "    \"\"\"\n",
    "    t_signal = np.array(t_signal)\n",
    "    t_signal_length = len(t_signal) \n",
    "#     print(\"number of sample points in t_signal\", t_signal_length)\n",
    "    \n",
    "    # 1D numpy array containing complex values\n",
    "    f_signal = fft(t_signal) \n",
    "    \n",
    "    # generate frequencies associated to f_signal complex values\n",
    "    # frequency values between [-10hz:+10hz]\n",
    "    freqs = np.array(sp.fftpack.fftfreq(t_signal_length, d = 1/float(sampling_freq))) \n",
    "    \n",
    "    f_DC_signal = [] # DC_component in freq domain\n",
    "    f_body_signal = [] # body component in freq domain \n",
    "    f_noise_signal = [] # noise in freq domain\n",
    "    \n",
    "    # iterate over all available frequencies\n",
    "    for i, freq in enumerate(freqs):\n",
    "          \n",
    "        # selecting the f_signal value associated to freq\n",
    "        value = f_signal[i]\n",
    "        \n",
    "        # Selecting DC_component values \n",
    "        if abs(freq) > cutoff:\n",
    "            f_DC_signal.append(float(0))                                       \n",
    "        else: \n",
    "            f_DC_signal.append(value) \n",
    "    \n",
    "        # Selecting noise component values \n",
    "        if (abs(freq) <= maxfreq):\n",
    "            f_noise_signal.append(float(0))  \n",
    "        else:\n",
    "            f_noise_signal.append(value) \n",
    "\n",
    "        # Selecting body_component values \n",
    "        if (abs(freq) <= cutoff or abs(freq) > maxfreq):\n",
    "            f_body_signal.append(float(0))\n",
    "        else:\n",
    "            f_body_signal.append(value) \n",
    "    \n",
    "   \n",
    "    t_DC_component = ifft(np.array(f_DC_signal)).real\n",
    "    t_body_component = ifft(np.array(f_body_signal)).real\n",
    "    t_noise = ifft(np.array(f_noise_signal)).real\n",
    "    \n",
    "    # extracting the total component(filtered from noise)\n",
    "    total_component = t_signal - t_noise  \n",
    "                                     \n",
    "    return (total_component,t_DC_component,t_body_component,t_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d749c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_domain_feature_gen(df, cutoff, maxfreq, sampling_freq):\n",
    "    \"\"\"\n",
    "    For each trial of a dance move by a subject, generate a df containing time domain features and update the time_sig_dic\n",
    "    Input : df i.e. df containing 1 min readings of 6 axial data of each trial of a dance move \n",
    "    Input : cutoff\n",
    "    Input : maxfreq\n",
    "    Input : name_for_df, i.e. key to represent the df for which time domain features were generated \n",
    "    Input : sampling_freq\n",
    "    Returns : dframe with 9 axial values generated from raw data \n",
    "    \"\"\"\n",
    "    time_sig = {}\n",
    "    \n",
    "    # iterate through all six axial signals \n",
    "    for column in df.columns:\n",
    "        t_signal = np.array(df[column])\n",
    "        medfiltered_sig = filter_signal(t_signal)\n",
    "        \n",
    "        if 'acc' in column: \n",
    "            _,grav_acc,body_acc,_ = t_domain_feature_per_signal(medfiltered_sig,cutoff,maxfreq,sampling_freq) \n",
    "            time_sig['t_body_'+ column] = body_acc\n",
    "            time_sig['t_grav_'+ column] = grav_acc \n",
    "            \n",
    "        elif 'gyro' in column: \n",
    "            _,_,body_gyro,_ = t_domain_feature_per_signal(medfiltered_sig,cutoff,maxfreq, sampling_freq)\n",
    "            time_sig['t_body_gyro_'+ column[-1]] = body_gyro\n",
    "    \n",
    "    \n",
    "    # all 9 axial signals generated above are reordered to facilitate find magnitude\n",
    "    new_columns_ordered = ['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n",
    "                          't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n",
    "                          't_body_gyro_X','t_body_gyro_Y','t_body_gyro_Z']\n",
    "    \n",
    "    \n",
    "    ordered_time_sig_df = pd.DataFrame()\n",
    "    for col in new_columns_ordered: \n",
    "        ordered_time_sig_df[col] = time_sig[col] \n",
    "    \n",
    "    # Calculating magnitude by iterating over each 3-axial signal\n",
    "    for i in range(0,9,3): \n",
    "        mag_col_name = new_columns_ordered[i][:-1]+'mag'\n",
    "        x_col = np.array(ordered_time_sig_df[new_columns_ordered[i]])   # copy X_component\n",
    "        y_col = np.array(ordered_time_sig_df[new_columns_ordered[i+1]]) # copy Y_component\n",
    "        z_col = np.array(ordered_time_sig_df[new_columns_ordered[i+2]]) # copy Z_component\n",
    "        \n",
    "        mag_signal = mag_3_signals(x_col,y_col,z_col) # calculate magnitude of each signal[X,Y,Z]\n",
    "        ordered_time_sig_df[mag_col_name] = mag_signal \n",
    "    \n",
    "    return ordered_time_sig_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9100916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_dataset(raw_dic, cutoff, maxfreq, sampling_freq, mapping_dic):\n",
    "    \"\"\"\n",
    "    Get final processed data for segmentation \n",
    "    Input: raw_dic i.e. raw_test or raw_train dict which contains each {subjectName}_{dance}_{trialNum}'s sensor data\n",
    "    Inputs: cutoff, maxfreq, sampling_freq\n",
    "    Input : mapping_dic i.e. to map dancemove to target as an integer, DANCE to NUM\n",
    "    Returns: final_dic with the keys as {subjectName}_{dance}_{trialNum} with processed data that has 16 cols \n",
    "    \"\"\"\n",
    "    final_dic = {}\n",
    "    for key in raw_dic.keys():\n",
    "        df = time_domain_feature_gen(raw_dic[key].drop([\"subject\", \"trialNum\", \"dance\"], axis = 1), cutoff, maxfreq, sampling_freq)\n",
    "        sub = np.unique(raw_dic[key][\"subject\"])\n",
    "        trial = np.unique(raw_dic[key][\"trialNum\"])\n",
    "        dancemove = np.unique(raw_dic[key][\"dance\"])\n",
    "        df[\"subject\"] = raw_dic[key][\"subject\"]\n",
    "        df[\"trialNum\"] = raw_dic[key][\"trialNum\"]\n",
    "        df[\"dance\"] = raw_dic[key][\"dance\"]\n",
    "        df[\"target\"] = df[\"dance\"].map(mapping_dic)\n",
    "        final_dic[f\"{sub}_{dancemove}_{trial}\"] = df\n",
    "        \n",
    "    return final_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b3f67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mapping(danceArray):\n",
    "    \"\"\"\n",
    "    Get two dicts. One with dance mapped to number and the other with number mapped to dance \n",
    "    Input: Unique dance moves in 1d array\n",
    "    Returns: ({dance: num}, {num: dance})\n",
    "    \"\"\"\n",
    "    map_dance_to_num = {}\n",
    "    map_num_to_dance = {}\n",
    "    for i, move in enumerate(danceArray): \n",
    "        map_num_to_dance[i] = move\n",
    "        map_dance_to_num[move] = i\n",
    "    return (map_dance_to_num, map_num_to_dance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26114f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputVector(reshapedSegments, samplingFreq, window, numOfAxis):\n",
    "    input_features = samplingFreq * window * numOfAxis\n",
    "    inputVector = reshapedSegments.reshape(reshapedSegments.shape[0], input_features)\n",
    "    return inputVector.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3d9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(df,samplingFreq,window,overlap,encodedTargetColumn, axisCount):\n",
    "    \"\"\"\n",
    "    Inputs: df, samplingFreq, window,overlap, encodedTargetColumn\n",
    "    Note : window = the time interval of one window in seconds,\n",
    "    overlap = num of steps to take from one segment/window to the next i.e. if 50% => 50 steps \n",
    "    \"\"\"\n",
    "#     window size = nrows = Sampling freq(Hz) * window(secs)\n",
    "#     if overlap = nrows, then there is no overlap bewteen segments,\n",
    "#     if accx,y,z and gyrox,y,z => 6 as numOfAxis. \n",
    "    numOfAxis = axisCount\n",
    "    segments = []\n",
    "    labels = []\n",
    "    nrows = samplingFreq * window\n",
    "    for i in range(0, len(df) - nrows, overlap): \n",
    "        bax = df[\"t_body_acc_X\"].values[i:i+nrows]\n",
    "        bay = df[\"t_body_acc_Y\"].values[i:i+nrows]\n",
    "        baz = df[\"t_body_acc_Z\"].values[i:i+nrows]\n",
    "        gx = df[\"t_grav_acc_X\"].values[i:i+nrows]\n",
    "        gy = df[\"t_grav_acc_Y\"].values[i:i+nrows]\n",
    "        gz = df[\"t_grav_acc_Z\"].values[i:i+nrows]\n",
    "        bgx = df[\"t_body_gyro_X\"].values[i:i+nrows]\n",
    "        bgy = df[\"t_body_gyro_Y\"].values[i:i+nrows]\n",
    "        bgz = df[\"t_body_gyro_Z\"].values[i:i+nrows]\n",
    "        bam = df[\"t_body_acc_mag\"].values[i:i+nrows]\n",
    "        gam = df[\"t_grav_acc_mag\"].values[i:i+nrows]\n",
    "        bgm = df[\"t_body_gyro_mag\"].values[i:i+nrows]\n",
    "        # retrieve the most used label in this segment \n",
    "        label = stats.mode(df[encodedTargetColumn][i:i+nrows])[0][0]\n",
    "        # each segment appended represents a window's values for each of \n",
    "        # the axial values\n",
    "        segments.append([bax,bay,baz,gx,gy,gz,bgx,bgy,bgz,bam,gam,bgm])\n",
    "        labels.append(label)\n",
    "    \n",
    "    reshaped_segments = np.asarray(segments,dtype =np.float32).reshape(-1,nrows,numOfAxis)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    # reshaped_segments will be x and labels will be y \n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b77d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUp(dframe,sub,trialNum, dance):\n",
    "    \"\"\"\n",
    "    Lookup a particular subject's values based on trialNum and dance in the raw dataframe \n",
    "    Inputs: dataframe, str(subject), str(trialNumber) and str(danceMove)\n",
    "    Returns: the dataframe under consideration.\n",
    "    \"\"\"\n",
    "    df_considered = dframe[(dframe[\"subject\"] == sub) & (dframe[\"trialNum\"] == trialNum) & (dframe[\"dance\"] == dance)]\n",
    "    return df_considered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34ce1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliseData(dframe, columnNames):\n",
    "    \"\"\"\n",
    "    Normalize features for training data set (values between 0 and 1).Columns rounded to 4dp after normalisation\n",
    "    Inputs: dframe and the list of columns to be normalised\n",
    "    No return value\n",
    "    \"\"\"\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    for col in columnNames:\n",
    "        dframe[col] = dframe[col] / dframe[col].max()\n",
    "        dframe[col] = dframe[col].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7306c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rawData(given_filepaths):\n",
    "    \"\"\"\n",
    "    Generate training and test dataframes from raw sensor data \n",
    "    Input: given_filepaths: filepaths 1D array\n",
    "    Returns: dictionary of raw dfs, with key being {subjectName}_{dance}_{trialNum}\n",
    "    \"\"\"\n",
    "    frames = {}\n",
    "    # each filepath corresponds to a diff file \n",
    "    # each file has 1200 values, each subject does a dance move for 3 times \n",
    "    # hence 3600 values per subject for a dance move \n",
    "    # thus for n dance moves, each subject has 3600 * n values \n",
    "    # with k subjects, the dataset will have k * 3600 * n values \n",
    "    for filepath in given_filepaths:\n",
    "        _, s, subjectName, ext = filepath.split(\"_\")\n",
    "        _, _, dance = s.split(\"/\")\n",
    "        trialNum, _ = ext.split(\".\")\n",
    "        raw_df = pd.read_csv(filepath, names=SENSOR_COLS, index_col=None)\n",
    "        raw_df.dropna(inplace= True)\n",
    "        raw_df.drop([\"yaw\",\"pitch\",\"roll\"], axis=1, inplace=True)\n",
    "        raw_df.reset_index(drop=True,inplace=True)\n",
    "        for col in raw_df.columns:\n",
    "            raw_df[col] = raw_df[col].div(100).round(6)\n",
    "        normaliseData(raw_df, raw_df.columns)\n",
    "        raw_df[\"subject\"] = subjectName\n",
    "        raw_df[\"trialNum\"] = int(trialNum)\n",
    "        raw_df[\"dance\"] = dance\n",
    "#         print(raw_df.shape)\n",
    "#         print(raw_df.head(3))\n",
    "        frames[f\"{subjectName}_{dance}_{trialNum}\"] = raw_df\n",
    "    return frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fed429f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_dic = gen_rawData(load_data_paths(TEST_FILEPATH))\n",
    "raw_train_dic = gen_rawData(load_data_paths(TRAIN_FILEPATH))\n",
    "\n",
    "training_dic = generate_final_dataset(raw_train_dic,CUTOFF,MAXFREQ, SAMPLING_FREQ, DANCE_TO_NUM_MAP)\n",
    "testing_dic = generate_final_dataset(raw_test_dic,CUTOFF,MAXFREQ, SAMPLING_FREQ, DANCE_TO_NUM_MAP)\n",
    "test_df = pd.concat(testing_dic.values(), axis = 0, ignore_index=True)\n",
    "train_df = pd.concat(training_dic.values(), axis = 0, ignore_index=True)\n",
    "data_train, lbl_train = segmentation(train_df, SAMPLING_FREQ, WINDOW_SIZE, OVERLAP, \"target\", 12 )\n",
    "data_test, lbl_test  = segmentation(test_df,SAMPLING_FREQ, WINDOW_SIZE, OVERLAP, \"target\", 12)\n",
    "# raw_train = pd.concat(raw_train_dic.values(), axis = 0,  ignore_index=True)\n",
    "# raw_train[\"target\"] = raw_train[\"dance\"].map(DANCE_TO_NUM_MAP)\n",
    "# raw_test[\"target\"] = raw_test[\"dance\"].map(DANCE_TO_NUM_MAP)\n",
    "# lookUp(raw_test, \"sean\", 3, \"jamesbond\")\n",
    "# dance_to_num , num_to_dance = gen_mapping(np.unique(raw_train[\"dance\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42269f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 480)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_X = getInputVector(data_train, SAMPLING_FREQ, WINDOW_SIZE, 12)\n",
    "training_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc31859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lbl_train.shape)\n",
    "len(training_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45fc0c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 480)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_X = getInputVector(data_test, SAMPLING_FREQ, WINDOW_SIZE, 12)\n",
    "testing_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb8709bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbfa7d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "fold: 0 , training_loss: 9.902906640490983e-06\n",
      "fold: 0, 107 out of 108 = 99.07% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 1 , training_loss: 4.855413862969726e-06\n",
      "fold: 1, 106 out of 108 = 98.15% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 2 , training_loss: 4.329345301812282e-06\n",
      "fold: 2, 107 out of 108 = 99.07% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 3 , training_loss: 2.323725311725866e-06\n",
      "fold: 3, 107 out of 108 = 99.07% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 4 , training_loss: 1.116016960622801e-06\n",
      "fold: 4, 108 out of 108 = 100.00% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 5 , training_loss: 4.921612344332971e-07\n",
      "fold: 5, 108 out of 108 = 100.00% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 6 , training_loss: 2.53747174383534e-07\n",
      "fold: 6, 108 out of 108 = 100.00% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 7 , training_loss: 1.1172773639600564e-07\n",
      "fold: 7, 108 out of 108 = 100.00% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 8 , training_loss: 7.861412143483903e-08\n",
      "fold: 8, 108 out of 108 = 100.00% correct\n",
      "-----------------------\n",
      "-----------------------\n",
      "fold: 9 , training_loss: 4.893459504273778e-08\n",
      "fold: 9, 108 out of 108 = 100.00% correct\n",
      "-----------------------\n",
      "\n",
      "Done Training\n",
      "Max Validation Accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, h1, h2, out_features=OUT_FEATURES):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
    "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
    "        self.out = nn.Linear(h2, out_features)  # output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Instantiate the Model class using parameter defaults:\n",
    "torch.manual_seed(32)\n",
    "hidden_layer_1_nodes = 80\n",
    "hidden_layer_2_nodes = 40\n",
    "mlp = Model(in_features=training_X.shape[1], h1=hidden_layer_1_nodes, h2=hidden_layer_2_nodes)\n",
    "X_train = torch.FloatTensor(training_X)\n",
    "X_test = torch.FloatTensor(testing_X)\n",
    "y_train = torch.LongTensor(lbl_train)\n",
    "y_test = torch.LongTensor(lbl_test)\n",
    "# trainloader = DataLoader(X_train, batch_size=60, shuffle=True)\n",
    "# testloader = DataLoader(X_test, batch_size=60, shuffle=False)\n",
    "# len(X_important_train[0])\n",
    "\n",
    "\n",
    "k = 10       \n",
    "skfcv = StratifiedKFold(n_splits=k, shuffle=True, random_state=1)\n",
    "epochs = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.01)\n",
    "training_loss = {}\n",
    "train_batch_size = 108\n",
    "test_batch_size = 72\n",
    "val_acc = []\n",
    "# per fold \n",
    "for fold, (train_index, test_index) in enumerate(skfcv.split(X_train, y_train)):\n",
    "    x_train_fold, x_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "    train_combined = TensorDataset(x_train_fold, y_train_fold)\n",
    "    test_combined = TensorDataset(x_test_fold, y_test_fold)\n",
    "    trainloader = DataLoader(train_combined, batch_size=train_batch_size, shuffle=True)\n",
    "    testloader = DataLoader(test_combined, batch_size=test_batch_size, shuffle=False)\n",
    "    # per epoch\n",
    "    for i in range(epochs): \n",
    "        i+=1\n",
    "        # per batch \n",
    "        losses = [] \n",
    "        val_correct_preds = 0\n",
    "        count = 0 \n",
    "        for batch_idx, (data, target) in enumerate(trainloader):\n",
    "            mlp.train()\n",
    "             \n",
    "            # training \n",
    "            y_pred = mlp.forward(data)\n",
    "            loss = criterion(y_pred, target)\n",
    "            losses.append(loss)\n",
    "            \n",
    "            # backtracking \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "        \n",
    "        # validating \n",
    "        with torch.no_grad():\n",
    "            mlp.eval()\n",
    "            for val_batch_idx, (val_data, val_target) in enumerate(testloader):\n",
    "                y_out = mlp.forward(val_data)\n",
    "#                 print(y_out.shape[0])\n",
    "                for row in range(y_out.shape[0]):\n",
    "#                     print(\"predicted:\" , y_out[row].argmax())\n",
    "#                     print(\"actual: \", val_target[row])\n",
    "                    if y_out[row].argmax() == val_target[row]:\n",
    "                        val_correct_preds += 1\n",
    "                    count += 1\n",
    "\n",
    "            \n",
    "    # per fold         \n",
    "    with torch.no_grad():\n",
    "        training_loss[fold] = np.array(losses).mean()\n",
    "        print(\"-----------------------\")\n",
    "        print(f\"fold: {fold} , training_loss: {training_loss[fold]}\")\n",
    "        print(f\"fold: {fold}, {val_correct_preds} out of {count} = {100*val_correct_preds/count:.2f}% correct\")\n",
    "        print(\"-----------------------\")\n",
    "        val_acc.append(100*val_correct_preds/count)\n",
    "        count = 0\n",
    "\n",
    "print()\n",
    "print(\"Done Training\")\n",
    "print(\"Max Validation Accuracy: \",  np.array(val_acc).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3ac1999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.029345035552978516 execution time in seconds ---\n",
      "Loss with test set : 0.94963831\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    y_val = mlp.forward(X_test)\n",
    "    print(\"--- %s execution time in seconds ---\" % (time.time() - start_time))\n",
    "    loss = criterion(y_val, y_test)\n",
    "    print(f'Loss with test set : {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25c452c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "196 out of 216 = 90.74% correct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    preds = []\n",
    "    correct = 0\n",
    "    for i,data in enumerate(X_test):\n",
    "        y_val = mlp.forward(data)\n",
    "#         print(f'{i+1:2}. {str(y_val):38}  {y_test[i]}')\n",
    "#         print(y_val.argmax().item(),y_test[i], y_val.argmax() )\n",
    "        preds.append(y_val.argmax().item())\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "    print(f'\\n{correct} out of {len(y_test)} = {100*correct/len(y_test):.2f}% correct')\n",
    "    y_preds = torch.tensor(preds, dtype = torch.int64)\n",
    "    stacked = torch.stack((y_test,y_preds),dim=1)\n",
    "#     print(stacked.shape)\n",
    "#     print(stacked)\n",
    "    cmt = torch.zeros(OUT_FEATURES,OUT_FEATURES, dtype=torch.int64)\n",
    "    for p in stacked:\n",
    "        tl, pl = p.tolist()\n",
    "#         print(tl,pl)\n",
    "        cmt[tl, pl] = cmt[tl, pl] + 1   \n",
    "#     print(cmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5a7b65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for MLP :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        72\n",
      "           1       0.92      0.94      0.93        72\n",
      "           2       0.95      0.88      0.91        72\n",
      "\n",
      "    accuracy                           0.91       216\n",
      "   macro avg       0.91      0.91      0.91       216\n",
      "weighted avg       0.91      0.91      0.91       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for MLP :\")\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c00e8106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'out.weight', 'out.bias'])\n",
      "fc1.weight : 80 neurons in fc1.weight layer\n",
      " number of connections  : 80 * 480 = 38400 \n",
      "fc1.bias : 80 neurons in fc1.bias layer\n",
      " number of connections  : 80 * 1 = 80 \n",
      "fc2.weight : 40 neurons in fc2.weight layer\n",
      " number of connections  : 40 * 80 = 3200 \n",
      "fc2.bias : 40 neurons in fc2.bias layer\n",
      " number of connections  : 40 * 1 = 40 \n",
      "out.weight : 3 neurons in out.weight layer\n",
      " number of connections  : 3 * 40 = 120 \n",
      "out.bias : 3 neurons in out.bias layer\n",
      " number of connections  : 3 * 1 = 3 \n",
      "0.94963831\n",
      "tensor([-0.3545, -0.2527, -0.2529, -0.2449, -0.2443, -0.2433, -0.2735, -0.4293,\n",
      "        -0.4272,  1.0320,  1.0349,  1.0382,  0.9473, -0.6945, -0.6902, -0.4022,\n",
      "        -0.2950, -0.2899, -0.0562,  0.1620,  0.1678,  0.0083, -0.0172,  0.0204,\n",
      "         0.0345,  0.0407, -0.1972, -0.4115, -0.4920, -0.4859,  0.8429,  1.1950,\n",
      "         1.2006, -0.3530, -0.3637, -0.3430, -0.3070, -0.1531, -0.1806, -0.1455,\n",
      "         0.5445,  0.5455,  0.4992,  0.5004,  0.5017,  0.3772,  0.0636,  0.0179,\n",
      "         0.0037, -0.1363, -0.2999, -0.5028, -0.5009, -0.3494, -0.1584, -0.1092,\n",
      "        -0.0992, -0.0577,  0.0073,  0.2377,  0.3028,  0.3049,  0.3070,  0.2854,\n",
      "         0.2323,  0.0453,  0.0078, -0.0534, -0.1698, -0.2941, -0.4893, -0.4878,\n",
      "        -0.4157, -0.3435, -0.3424, -0.2232, -0.1042,  0.1406,  0.6216,  0.6221,\n",
      "         0.4707,  0.1525,  0.1516,  0.1905,  0.3164,  0.3155,  0.2749,  0.2501,\n",
      "        -0.0049, -0.3949, -0.4358, -0.4370, -0.2874, -0.0030,  0.2179,  0.2165,\n",
      "         0.1040,  0.0073,  0.0058,  0.0043, -0.2115, -0.3798, -0.3814, -0.1687,\n",
      "        -0.1384, -0.0051,  0.1282,  0.1267,  0.0855,  0.0524, -0.0204, -0.0933,\n",
      "        -0.2532, -0.2544, -0.1682, -0.0503,  0.0838,  0.3846,  0.3838,  0.2324,\n",
      "        -0.1652, -0.1646, -0.1644, -0.1645, -0.1651, -0.1661, -0.1674, -0.1691,\n",
      "        -0.1712, -0.1737, -0.1766, -0.1799, -0.1835, -0.1874, -0.1917, -0.1962,\n",
      "        -0.2011, -0.2062, -0.2115, -0.2171, -0.2229, -0.2288, -0.2348, -0.2409,\n",
      "        -0.2471, -0.2533, -0.2595, -0.2657, -0.2718, -0.2779, -0.2838, -0.2895,\n",
      "        -0.2951, -0.3005, -0.3056, -0.3105, -0.3150, -0.3193, -0.3233, -0.3269,\n",
      "        -0.0878, -0.0888, -0.0898, -0.0910, -0.0923, -0.0937, -0.0951, -0.0966,\n",
      "        -0.0982, -0.0999, -0.1017, -0.1035, -0.1054, -0.1073, -0.1093, -0.1113,\n",
      "        -0.1134, -0.1155, -0.1175, -0.1196, -0.1217, -0.1238, -0.1259, -0.1279,\n",
      "        -0.1299, -0.1319, -0.1338, -0.1356, -0.1373, -0.1390, -0.1406, -0.1421,\n",
      "        -0.1434, -0.1447, -0.1458, -0.1469, -0.1478, -0.1485, -0.1492, -0.1497,\n",
      "        -0.4628, -0.4620, -0.4611, -0.4603, -0.4593, -0.4584, -0.4574, -0.4564,\n",
      "        -0.4554, -0.4543, -0.4531, -0.4519, -0.4507, -0.4494, -0.4481, -0.4467,\n",
      "        -0.4453, -0.4438, -0.4423, -0.4408, -0.4393, -0.4377, -0.4361, -0.4345,\n",
      "        -0.4330, -0.4314, -0.4298, -0.4283, -0.4268, -0.4254, -0.4240, -0.4226,\n",
      "        -0.4214, -0.4202, -0.4191, -0.4180, -0.4171, -0.4163, -0.4155, -0.4149,\n",
      "        -0.2913, -0.2917, -0.1379,  0.0981,  0.0979, -0.0079, -0.0841, -0.3723,\n",
      "        -0.8253, -0.8792, -0.8791, -0.5129, -0.1968, -0.0298, -0.0294, -0.3092,\n",
      "        -0.3088, -0.1461,  0.0732,  0.0737, -0.1324, -0.1632, -0.1627,  0.0272,\n",
      "         0.0508,  0.2749,  0.2754,  0.2161,  0.1425,  0.1429,  0.3443,  0.4524,\n",
      "         0.5480,  0.6014,  0.6015,  0.5962,  0.4787,  0.4226, -0.0097, -0.3127,\n",
      "         0.0527,  0.0476,  0.0103,  0.0120, -0.1396, -0.1377, -0.0298,  0.1320,\n",
      "         0.1919,  0.1974,  0.1993, -0.0144, -0.0615, -0.2794, -0.2777, -0.1624,\n",
      "         0.1007,  0.3936,  0.3949,  0.4158,  0.1339,  0.0509, -0.1622, -0.1638,\n",
      "        -0.3155, -0.3152, -0.1916,  0.0038,  0.2168,  0.2479,  0.2161,  0.0089,\n",
      "        -0.0792, -0.1183, -0.1193,  0.0358,  0.2180,  0.2342,  0.2327, -0.0840,\n",
      "         0.4058,  0.1524, -0.0637, -0.2012, -0.2306, -0.2302, -0.1443, -0.1436,\n",
      "        -0.1572, -0.1573, -0.1564, -0.3455, -0.4616, -0.5916, -0.5905, -0.5084,\n",
      "        -0.1916,  0.1246,  0.2706,  0.2830,  0.2730,  0.0126, -0.2512, -0.2501,\n",
      "        -0.2466, -0.0409,  0.0111,  0.0385,  0.3318,  0.5791,  0.5795,  0.4827,\n",
      "         0.2400,  0.0635, -0.0447, -0.0450,  0.2640,  0.4302,  0.6740,  0.6732,\n",
      "         0.8023,  0.6202,  0.5798,  0.5888,  0.6415,  0.5486,  0.3930,  0.4972,\n",
      "         0.4272,  1.1134,  1.1623,  1.2335,  1.1094,  0.7774,  0.7409,  0.4696,\n",
      "         0.3282,  0.2957,  0.0569,  0.2877,  0.4057,  0.4871,  0.4899,  0.3322,\n",
      "         0.2726,  0.0611,  0.2353,  0.4339,  0.5274,  0.5704,  0.9748,  1.2941,\n",
      "         1.2955,  0.5544,  0.5271,  0.4124,  0.3348,  0.4372,  0.7525,  0.6798,\n",
      "         0.4992,  0.4984,  0.4977,  0.4972,  0.4968,  0.4965,  0.4963,  0.4962,\n",
      "         0.4963,  0.4965,  0.4968,  0.4973,  0.4979,  0.4986,  0.4995,  0.5004,\n",
      "         0.5016,  0.5028,  0.5042,  0.5057,  0.5074,  0.5092,  0.5111,  0.5131,\n",
      "         0.5152,  0.5174,  0.5196,  0.5220,  0.5243,  0.5268,  0.5292,  0.5316,\n",
      "         0.5341,  0.5364,  0.5388,  0.5410,  0.5432,  0.5453,  0.5472,  0.5490,\n",
      "         0.5023,  0.3325,  0.1523,  0.2242,  0.2868,  0.2683,  0.1696,  0.4203,\n",
      "         0.8618,  0.9148,  0.9149,  0.6186,  0.5055,  0.6549,  0.6532,  0.6168,\n",
      "         0.3771,  0.4379,  0.4843,  0.5083,  0.3316,  0.1714,  0.3404,  0.3002,\n",
      "         0.4037,  0.4202,  0.3357,  0.2195,  0.4212,  0.6460,  0.7079,  0.6616,\n",
      "         0.6035,  0.6162,  0.6148,  0.5990,  0.5885,  0.6469,  0.7131,  0.7470])\n",
      "tensor([-47.6068,  32.4533, -57.4527])\n",
      "\n",
      "tensor(32.4533)\n",
      "1\n",
      "Predicted Output: jamesbond\n",
      "Actual Output: jamesbond\n"
     ]
    }
   ],
   "source": [
    "# model weights \n",
    "with torch.no_grad():\n",
    "    mlp_params = {}\n",
    "    for name, param in mlp.named_parameters():\n",
    "#         print(name,param)\n",
    "        mlp_params[name] = param.numpy().copy().tolist()\n",
    "print(mlp_params.keys())\n",
    "for key in mlp_params.keys(): \n",
    "    print(f\"{key} : {len(mlp_params[key])} neurons in {key} layer\")\n",
    "    print(f\" number of connections  : {len(mlp_params[key])} * {np.asarray(mlp_params[key][len(mlp_params[key]) -1]).size} = {len(mlp_params[key]) * np.asarray(mlp_params[key][len(mlp_params[key]) -1]).size } \")\n",
    "    \n",
    "    \n",
    "torch.save(mlp.state_dict(), 'MLPW9.pt')\n",
    "\n",
    "loaded_model = Model(in_features=len(training_X[1]),h1=80, h2=40)\n",
    "loaded_model.load_state_dict(torch.load('MLPW9.pt'))\n",
    "loaded_model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_val = loaded_model.forward(X_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'{loss:.8f}')\n",
    "\n",
    "random.seed(99)\n",
    "random_int = random.randint(0, len(testing_X))\n",
    "random_input = torch.FloatTensor(testing_X[random_int])\n",
    "print(random_input)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(loaded_model(random_input))\n",
    "    print()\n",
    "    print(loaded_model(random_input).max())\n",
    "    print(loaded_model(random_input).argmax().item())\n",
    "    print(f\"Predicted Output: {NUM_TO_DANCE_MAP[loaded_model(random_input).argmax().item()]}\")\n",
    "    print(f\"Actual Output: {NUM_TO_DANCE_MAP[y_test[random_int].item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c941a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mlp.csv', 'w') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in mlp_params.items():\n",
    "       writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f45e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(): \n",
    "    x = X_test.numpy().copy().tolist()\n",
    "    np.savetxt(\"X_test.csv\", x, delimiter=\",\")\n",
    "    y = y_test.numpy().copy().tolist()\n",
    "    np.savetxt(\"y_test.csv\", y, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
