{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0646188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import medfilt\n",
    "from scipy.fftpack import fft \n",
    "from scipy.fftpack import fftfreq \n",
    "from scipy.fftpack import ifft \n",
    "from numpy.fft import *\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba27080",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_FREQ = 20 # Hz\n",
    "WINDOW_SIZE = 2 # seconds\n",
    "OVERLAP = int((SAMPLING_FREQ * WINDOW_SIZE) / 2) # no of rows (readings) to drop from the front = no.of rows as steps forward  \n",
    "NYQ = SAMPLING_FREQ / float(2) # Nyquist frequency \n",
    "\n",
    "\n",
    "CUTOFF = 0.3 \n",
    "MAXFREQ = 10 \n",
    "\n",
    "DANCE_MOVES = [\"jamesbond\", \"dab\", \"mermaid\"]\n",
    "SENSOR_COLS = [\"acc_X\", \"acc_Y\", \"acc_Z\", \"gyro_X\", \"gyro_Y\", \"gyro_Z\"]\n",
    "\n",
    "READING_SIZE = SAMPLING_FREQ * WINDOW_SIZE # received sensor data length = SEGMENT SIZE \n",
    "NUM_OF_LIVE_SENSOR_COLS = 6\n",
    "FEATURE_COLS = 12 \n",
    "\n",
    "CUMULATIVE_DATA = np.zeros((1,FEATURE_COLS), dtype=float, order='C') # holds rows of sensor data with 12 extracted cols\n",
    "CUMULATIVE_DATA = np.delete(CUMULATIVE_DATA, 0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b74e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliseData(dframe):\n",
    "    \"\"\"\n",
    "    Normalize features for training data set (values between 0 and 1). Columns rounded to 4dp after normalisation.\n",
    "    Input: dframe \n",
    "    No return value\n",
    "    \"\"\"\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    for col in dframe.columns:\n",
    "#         print(col)\n",
    "        dframe[col] = dframe[col].div(100).round(6) # received sensor data were scaled by 100\n",
    "        dframe[col] = dframe[col] / dframe[col].max()\n",
    "        dframe[col] = dframe[col].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da7fdccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDframeForFeatureGeneration(array):\n",
    "    \"\"\"\n",
    "    From the 40 x 6 Numpy Array, create a dframe, normalise \n",
    "    and prepare for feature generation. \n",
    "    Input : 2D Numpy array of shape 40 x 6 \n",
    "    Return : df of shape 40 rows * 6 cols \n",
    "    \"\"\"\n",
    "    \n",
    "    global SENSOR_COLS\n",
    "    \n",
    "    df = pd.DataFrame(data=array, index=None, columns=SENSOR_COLS)\n",
    "    normaliseData(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e565ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(signal):\n",
    "    \"\"\"\n",
    "    Applies 3rd order median filter for each signal i.e. Each axial column in dataset.\n",
    "    Input: 1D Numpy array for each axial column \n",
    "    Return: 3rd order median-filtered signal i.e.1D Numpy array \n",
    "    \"\"\"\n",
    "    array = np.array(signal)   \n",
    "    med_filtered = medfilt(array, kernel_size=3) \n",
    "    return  med_filtered  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb791c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_domain_feature_per_signal(t_signal):\n",
    "    \"\"\"\n",
    "    For each time-domain signal, i.e. accx,y,z and gyrox,y,z, split into their respective time-domain components. \n",
    "    Pass the entire column and get the corresponding time domain components.\n",
    "    Input: t_signal i.e. 1D Numpy array (time domain signal)\n",
    "    Returns: (total_component, t_DC_component , t_body_component, t_noise)\n",
    "    \"\"\"\n",
    "    \n",
    "    global CUTOFF, MAXFREQ, SAMPLING_FREQ\n",
    "    \n",
    "    \n",
    "    t_signal = np.array(t_signal)\n",
    "    t_signal_length = len(t_signal) # num of sample pts in t_signal i.e. For e.g. 40 for received live sensor data \n",
    "\n",
    "    # 1D numpy array containing complex values\n",
    "    f_signal = fft(t_signal) \n",
    "    \n",
    "    # generate frequencies associated to f_signal complex values\n",
    "    # frequency values between [-10hz:+10hz]\n",
    "    freqs = np.array(sp.fftpack.fftfreq(t_signal_length, d = 1/float(SAMPLING_FREQ))) \n",
    "    \n",
    "    f_DC_signal = [] # DC_component in freq domain\n",
    "    f_body_signal = [] # body component in freq domain \n",
    "    f_noise_signal = [] # noise in freq domain\n",
    "    \n",
    "    # iterate over all available frequencies\n",
    "    for i, freq in enumerate(freqs):\n",
    "          \n",
    "        # selecting the f_signal value associated to freq\n",
    "        value = f_signal[i]\n",
    "        \n",
    "        # Selecting DC_component values \n",
    "        if abs(freq) > CUTOFF:\n",
    "            f_DC_signal.append(float(0))                                       \n",
    "        else: \n",
    "            f_DC_signal.append(value) \n",
    "    \n",
    "        # Selecting noise component values \n",
    "        if (abs(freq) <= MAXFREQ):\n",
    "            f_noise_signal.append(float(0))  \n",
    "        else:\n",
    "            f_noise_signal.append(value) \n",
    "\n",
    "        # Selecting body_component values \n",
    "        if (abs(freq) <= CUTOFF or abs(freq) > MAXFREQ):\n",
    "            f_body_signal.append(float(0))\n",
    "        else:\n",
    "            f_body_signal.append(value) \n",
    "    \n",
    "   \n",
    "    t_DC_component = ifft(np.array(f_DC_signal)).real\n",
    "    t_body_component = ifft(np.array(f_body_signal)).real\n",
    "    t_noise = ifft(np.array(f_noise_signal)).real\n",
    "    \n",
    "    # extracting the total component(filtered from noise)\n",
    "    total_component = t_signal - t_noise  \n",
    "                                     \n",
    "    return (total_component,t_DC_component,t_body_component,t_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a64f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_3_signals(x,y,z): \n",
    "    \"\"\"\n",
    "    Finds Euclidian magnitude of 3-axial signal.\n",
    "    Inputs: x, y , z columns (Numpy arrays)\n",
    "    Return: Euclidian magnitude of each set of x,y,z i.e. each sample reading's mag\n",
    "    \"\"\"\n",
    "    return [math.sqrt((x[i]**2+y[i]**2+z[i]**2)) for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c81c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_domain_feature_gen(df):\n",
    "    \"\"\"\n",
    "    Generates as df with time domain features. This should yield 12 feature cols of data. \n",
    "    Input : df i.e. df containing 1 min readings of 6 axial data of each trial of a dance move \n",
    "    Returns : dframe with 12 axial values derived from raw data \n",
    "    \"\"\"\n",
    "    \n",
    "    global SAMPLING_FREQ, CUTOFF, MAXFREQ\n",
    "    \n",
    "    time_sig = {}\n",
    "    \n",
    "    # iterate through all six axial signals \n",
    "    for column in df.columns:\n",
    "        t_signal = np.array(df[column])\n",
    "        medfiltered_sig = filter_signal(t_signal)\n",
    "        \n",
    "        if 'acc' in column: \n",
    "            _,grav_acc,body_acc,_ = t_domain_feature_per_signal(medfiltered_sig) \n",
    "            time_sig['t_body_'+ column] = body_acc\n",
    "            time_sig['t_grav_'+ column] = grav_acc \n",
    "            \n",
    "        elif 'gyro' in column: \n",
    "            _,_,body_gyro,_ = t_domain_feature_per_signal(medfiltered_sig)\n",
    "            time_sig['t_body_gyro_'+ column[-1]] = body_gyro\n",
    "    \n",
    "    \n",
    "    # all 9 axial signals generated above are reordered to facilitate finding magnitude\n",
    "    new_columns_ordered = ['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n",
    "                          't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n",
    "                          't_body_gyro_X','t_body_gyro_Y','t_body_gyro_Z']\n",
    "    \n",
    "    \n",
    "    # generate a new df from the time_sig dict\n",
    "    ordered_time_sig_df = pd.DataFrame()\n",
    "    for col in new_columns_ordered: \n",
    "        ordered_time_sig_df[col] = time_sig[col] \n",
    "    \n",
    "    # Calculating magnitude by iterating over each 3-axial signal\n",
    "    for i in range(0,9,3): \n",
    "        mag_col_name = new_columns_ordered[i][:-1]+'mag'\n",
    "        x_col = np.array(ordered_time_sig_df[new_columns_ordered[i]])   # copy X_component\n",
    "        y_col = np.array(ordered_time_sig_df[new_columns_ordered[i+1]]) # copy Y_component\n",
    "        z_col = np.array(ordered_time_sig_df[new_columns_ordered[i+2]]) # copy Z_component\n",
    "        \n",
    "        mag_signal = mag_3_signals(x_col,y_col,z_col) # calculate magnitude of each signal[X,Y,Z]\n",
    "        ordered_time_sig_df[mag_col_name] = mag_signal \n",
    "    \n",
    "    return ordered_time_sig_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f33f0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_global(): \n",
    "    \"\"\"\n",
    "    Extracts the required window from the global list. \n",
    "    Return : Extracted window of 2D array, i.e. expected 2D Numpy array of shape 40 * 12 \n",
    "    \"\"\"\n",
    "    \n",
    "    global CUMULATIVE_DATA, OVERLAP, READING_SIZE\n",
    "    \n",
    "    input_selected = CUMULATIVE_DATA[0:READING_SIZE] # 40 rows or data pts selected \n",
    "    CUMULATIVE_DATA = np.delete(CUMULATIVE_DATA, np.s_[0:OVERLAP], axis = 0) # pop first 20 \n",
    "    return input_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b14ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputVector(arr):\n",
    "    \"\"\"\n",
    "    Transform window of 40 data points into a single 1D array representing each window to be fed into nn. \n",
    "    Input: 2D Numpy arr of expected shape 40 * 12 \n",
    "    Return: inputVector for nn, i.e. 1 x (40rows * 12features)\n",
    "    \"\"\"\n",
    "    global READING_SIZE, FEATURE_COLS\n",
    "    \n",
    "#     segments = []\n",
    "    ncols = READING_SIZE * FEATURE_COLS\n",
    "#     for i in range(0,arr.shape[1]): \n",
    "#         segments.append(arr[:,i])\n",
    "#     reshaped_segments = np.asarray(segments,dtype=np.float32).reshape(-1,READING_SIZE,FEATURE_COLS)\n",
    "#     invec = reshaped_segments.reshape(reshaped_segments.shape[0], ncols)\n",
    "    invec = arr.reshape(1, ncols)\n",
    "    return invec.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "575038fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append(data):\n",
    "    \"\"\"\n",
    "    Each row of live sensor data of 6 axial values, will be pre-processed & extracted into 12 feature columns \n",
    "    and appended to a global 2D Numpy array. \n",
    "    From the global 2D Numpy array, a window of readings will be selected \n",
    "    to form a input vector of shape 1 x 480 to be fed into the nn.\n",
    "    Input: data, i.e. 2D Numpy array of shape (40,6) is preferred \n",
    "    Returns: 1 x (40 * 12 ) Numpy array to be fed as input to nn model and it's shape\n",
    "    \"\"\"\n",
    "    global CUMULATIVE_DATA , NUM_OF_LIVE_SENSOR_COLS, READING_SIZE\n",
    "    \n",
    "    \n",
    "    arr = np.array(data)\n",
    "    \n",
    "    # padding \n",
    "    if len(arr) < READING_SIZE:\n",
    "        leftover = READING_SIZE - len(arr)\n",
    "        padding = np.zeros((leftover, NUM_OF_LIVE_SENSOR_COLS),dtype=float, order='C')\n",
    "        arr = np.concatenate((arr,padding))\n",
    "        \n",
    "    # feature generation and update of global list \n",
    "    raw_df = generateDframeForFeatureGeneration(arr)\n",
    "    df = time_domain_feature_gen(raw_df)\n",
    "    CUMULATIVE_DATA = np.concatenate((CUMULATIVE_DATA, df.values))\n",
    "    selected_window = segment_global()\n",
    "    inputvector = getInputVector(selected_window)\n",
    "    print(\"cumulative data shape: \", CUMULATIVE_DATA.shape)\n",
    "    \n",
    "    return (inputvector, inputvector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "695e5e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for testing \n",
    "# df = pd.read_csv(\"./capstone_data/test/dab_sean_1.csv\", index_col=None, header = None )\n",
    "# iv, ivshape = append(np.asarray(df.values[0:40, 0:6]))\n",
    "# print(\"input vector shape:\", ivshape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
