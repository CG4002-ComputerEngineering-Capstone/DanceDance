{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b4ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sn\n",
    "plt.style.use('ggplot')\n",
    "sn.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import medfilt\n",
    "from scipy.fftpack import fft \n",
    "from scipy.fftpack import fftfreq \n",
    "from scipy.fftpack import ifft \n",
    "from numpy.fft import *\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81a47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_FREQ = 20 # Hz \n",
    "WINDOW_SIZE = 2 # sec \n",
    "OVERLAP = 20 # 20 steps forward and 20 steps from prev window \n",
    "SEGMENT_SIZE = SAMPLING_FREQ * WINDOW_SIZE # 40 \n",
    "FEATURE_COLS_LEN = 12 \n",
    "FEATURE_COLS = ['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n",
    "                't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n",
    "                't_body_gyro_X','t_body_gyro_Y','t_body_gyro_Z',\n",
    "                't_body_acc_mag','t_grav_acc_mag','t_body_gyro_mag']\n",
    "\n",
    "\n",
    "NYQ = SAMPLING_FREQ / float(2) # Nyquist frequency \n",
    "CUTOFF = 0.3 \n",
    "MAXFREQ = 10 \n",
    "\n",
    "\n",
    "DANCE_MOVES = [\"jamesbond\", \"dab\", \"mermaid\"]\n",
    "TRAIN_SUBJECTS = ['chekjun','haritha', 'matthew' ,'nishanth', 'priyan']\n",
    "SENSOR_COLS = [\"acc_X\", \"acc_Y\", \"acc_Z\", \"gyro_X\", \"gyro_Y\", \"gyro_Z\", \"yaw\", \"pitch\", \"roll\"]\n",
    "\n",
    "DANCE_TO_NUM_MAP = {'dab': 0, 'jamesbond': 1, 'mermaid': 2}\n",
    "NUM_TO_DANCE_MAP = {0: 'dab', 1: 'jamesbond', 2: 'mermaid'}\n",
    "\n",
    "TRAIN_FILEPATH = \"./capstone_data/train/*.csv\"\n",
    "TEST_FILEPATH = \"./capstone_data/test/*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a3216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_paths(location):\n",
    "    \"\"\"\n",
    "    Gets file path to each csv data file.\n",
    "    Input: filepath to csv files i.e. string\n",
    "    Return: 1D array of filepath to each csv which contains sensor data for each trial by a subject for a dance move \n",
    "    \"\"\"\n",
    "    data_paths = []\n",
    "    for name in glob.glob(location):\n",
    "        data_paths.append(name)\n",
    "    return data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d38869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliseData(dframe):\n",
    "    \"\"\"\n",
    "    Normalize features for training data set (values between 0 and 1). Columns rounded to 4dp after normalisation.\n",
    "    Input: raw dframe \n",
    "    No return value\n",
    "    \"\"\"\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    for col in dframe.columns:\n",
    "        dframe[col] = dframe[col].div(100).round(6) # sensor data was scaled by 100 \n",
    "        dframe[col] = dframe[col] / dframe[col].max()\n",
    "        dframe[col] = dframe[col].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f81b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rawData(given_filepaths):\n",
    "    \"\"\"\n",
    "    Generate training and test dataframes from raw sensor data. \n",
    "    Input: given_filepaths i.e. filepaths 1D array\n",
    "    Return: dictionary of raw dfs, with key being {subjectName}_{dance}_{trialNum}\n",
    "    \"\"\"\n",
    "    frames = {}\n",
    "    # each filepath corresponds to a diff csv file \n",
    "    # each file has 20 * 60s = 1200 values & each subject does a dance move for 3 times \n",
    "    # hence 3600 values per subject for a dance move \n",
    "    # thus for n dance moves, each subject has 3600 * n values \n",
    "    # with k subjects, the dataset will have k * 3600 * n values \n",
    "    for filepath in given_filepaths:\n",
    "        _, s, subjectName, ext = filepath.split(\"_\")\n",
    "        _, _, dance = s.split(\"/\")\n",
    "        trialNum, _ = ext.split(\".\")\n",
    "        raw_df = pd.read_csv(filepath, names=SENSOR_COLS, index_col=None)\n",
    "        raw_df.dropna(inplace= True)\n",
    "        raw_df.drop([\"yaw\",\"pitch\",\"roll\"], axis=1, inplace=True)\n",
    "        raw_df.reset_index(drop=True,inplace=True)\n",
    "        normaliseData(raw_df)\n",
    "        raw_df[\"subject\"] = subjectName\n",
    "        raw_df[\"trialNum\"] = int(trialNum)\n",
    "        raw_df[\"dance\"] = dance\n",
    "#         print(raw_df.shape)\n",
    "#         print(raw_df.head(3))\n",
    "        frames[f\"{subjectName}_{dance}_{trialNum}\"] = raw_df\n",
    "    return frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2b6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(signal):\n",
    "    \"\"\"\n",
    "    Applies 3rd order median filter for each signal i.e. Each axial column in dataset.\n",
    "    Input: 1D Numpy array i.e. one column\n",
    "    Return: 3rd order median-filtered signal i.e 1D Numpy array\n",
    "    \"\"\"\n",
    "    array = np.array(signal)   \n",
    "    med_filtered = medfilt(array, kernel_size=3) \n",
    "    return  med_filtered  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4f2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_3_signals(x,y,z): \n",
    "    \"\"\"\n",
    "    Finding Euclidian magnitude of 3-axial signal values of each row i.e. each sample point.\n",
    "    Inputs: x, y , z columns (1D Numpy arrays)\n",
    "    Return: Euclidian magnitude of each 3-axial signals\n",
    "    \"\"\"\n",
    "    return [math.sqrt((x[i]**2+y[i]**2+z[i]**2)) for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b45f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_domain_feature_per_signal(t_signal):\n",
    "    \"\"\"\n",
    "    For each time-domain signal, i.e. accx,y,z and gyrox,y,z, split into their respective time-domain components.\n",
    "    Input: t_signal i.e. 1D Numpy array (time domain signal - each column)\n",
    "    Returns: (total_component, t_DC_component , t_body_component, t_noise)\n",
    "    \"\"\"\n",
    "    \n",
    "    global CUTOFF, MAXFREQ, SAMPLING_FREQ\n",
    "    \n",
    "    t_signal = np.array(t_signal)\n",
    "    t_signal_length = len(t_signal) \n",
    "#     print(\"number of sample points in t_signal\", t_signal_length) \n",
    "    \n",
    "    # 1D numpy array containing complex values\n",
    "    f_signal = fft(t_signal) \n",
    "    \n",
    "    # generate frequencies associated to f_signal complex values\n",
    "    # frequency values between [-10hz:+10hz]\n",
    "    freqs = np.array(sp.fftpack.fftfreq(t_signal_length, d = 1/float(SAMPLING_FREQ))) \n",
    "    \n",
    "    f_DC_signal = [] # DC_component in freq domain\n",
    "    f_body_signal = [] # body component in freq domain \n",
    "    f_noise_signal = [] # noise in freq domain\n",
    "    \n",
    "    # iterate over all available frequencies\n",
    "    for i, freq in enumerate(freqs):\n",
    "          \n",
    "        # selecting the f_signal value associated to freq\n",
    "        value = f_signal[i]\n",
    "        \n",
    "        # Selecting DC_component values \n",
    "        if abs(freq) > CUTOFF:\n",
    "            f_DC_signal.append(float(0))                                       \n",
    "        else: \n",
    "            f_DC_signal.append(value) \n",
    "    \n",
    "        # Selecting noise component values \n",
    "        if (abs(freq) <= MAXFREQ):\n",
    "            f_noise_signal.append(float(0))  \n",
    "        else:\n",
    "            f_noise_signal.append(value) \n",
    "\n",
    "        # Selecting body_component values \n",
    "        if (abs(freq) <= CUTOFF or abs(freq) > MAXFREQ):\n",
    "            f_body_signal.append(float(0))\n",
    "        else:\n",
    "            f_body_signal.append(value) \n",
    "    \n",
    "   \n",
    "    t_DC_component = ifft(np.array(f_DC_signal)).real\n",
    "    t_body_component = ifft(np.array(f_body_signal)).real\n",
    "    t_noise = ifft(np.array(f_noise_signal)).real\n",
    "    \n",
    "    # extracting the total component(filtered from noise)\n",
    "    total_component = t_signal - t_noise  \n",
    "                                     \n",
    "    return (total_component,t_DC_component,t_body_component,t_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ecbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_domain_feature_gen(df):\n",
    "    \"\"\"\n",
    "    For each trial of a dance move by a subject, generate a df containing time domain features.\n",
    "    Input : df i.e. df containing 1 min readings of 6 axial data of each trial of a dance move \n",
    "    Return : dframe with 12 cols generated from raw data \n",
    "    \"\"\"    \n",
    "    time_sig = {}\n",
    "    \n",
    "    # iterate through all six axial signals \n",
    "    for column in df.columns:\n",
    "        t_signal = np.array(df[column])\n",
    "        medfiltered_sig = filter_signal(t_signal)\n",
    "        \n",
    "        if 'acc' in column: \n",
    "            _,grav_acc,body_acc,_ = t_domain_feature_per_signal(medfiltered_sig) \n",
    "            time_sig['t_body_'+ column] = body_acc\n",
    "            time_sig['t_grav_'+ column] = grav_acc \n",
    "            \n",
    "        elif 'gyro' in column: \n",
    "            _,_,body_gyro,_ = t_domain_feature_per_signal(medfiltered_sig)\n",
    "            time_sig['t_body_gyro_'+ column[-1]] = body_gyro\n",
    "    \n",
    "    \n",
    "    # all 9 axial signals generated above are reordered to facilitate find magnitude\n",
    "    new_columns_ordered = ['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n",
    "                          't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n",
    "                          't_body_gyro_X','t_body_gyro_Y','t_body_gyro_Z']\n",
    "    \n",
    "    \n",
    "    ordered_time_sig_df = pd.DataFrame()\n",
    "    for col in new_columns_ordered: \n",
    "        ordered_time_sig_df[col] = time_sig[col] \n",
    "    \n",
    "    # Calculating magnitude by iterating over each 3-axial signal\n",
    "    for i in range(0,9,3): \n",
    "        mag_col_name = new_columns_ordered[i][:-1]+'mag'\n",
    "        x_col = np.array(ordered_time_sig_df[new_columns_ordered[i]])   # copy X_component\n",
    "        y_col = np.array(ordered_time_sig_df[new_columns_ordered[i+1]]) # copy Y_component\n",
    "        z_col = np.array(ordered_time_sig_df[new_columns_ordered[i+2]]) # copy Z_component\n",
    "        \n",
    "        mag_signal = mag_3_signals(x_col,y_col,z_col) # calculate magnitude of each signal[X,Y,Z]\n",
    "        ordered_time_sig_df[mag_col_name] = mag_signal \n",
    "    \n",
    "    return ordered_time_sig_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "048351c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_dataset(raw_dic):\n",
    "    \"\"\"\n",
    "    Get final processed data for segmentation.\n",
    "    Input: raw_dic i.e. raw_test or raw_train dict which contains each {subjectName}_{dance}_{trialNum}'s sensor data\n",
    "    Return: final_dic with the keys as {subjectName}_{dance}_{trialNum} with processed data that has 16 cols \n",
    "    \"\"\"\n",
    "    global DANCE_TO_NUM_MAP\n",
    "    \n",
    "    final_dic = {}\n",
    "    for key in raw_dic.keys():\n",
    "        df = time_domain_feature_gen(raw_dic[key].drop([\"subject\", \"trialNum\", \"dance\"], axis = 1))\n",
    "        sub = np.unique(raw_dic[key][\"subject\"])\n",
    "        trial = np.unique(raw_dic[key][\"trialNum\"])\n",
    "        dancemove = np.unique(raw_dic[key][\"dance\"])\n",
    "        df[\"subject\"] = raw_dic[key][\"subject\"]\n",
    "        df[\"trialNum\"] = raw_dic[key][\"trialNum\"]\n",
    "        df[\"dance\"] = raw_dic[key][\"dance\"]\n",
    "        df[\"target\"] = df[\"dance\"].map(DANCE_TO_NUM_MAP)\n",
    "        final_dic[f\"{sub}_{dancemove}_{trial}\"] = df\n",
    "        \n",
    "    return final_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc6e4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenator(processed_dic):\n",
    "    \"\"\"\n",
    "    Concatenate processed_dic along the rows to generate train and test dframes which can be sent for segmentation.\n",
    "    Input: processed_dic\n",
    "    Return: concatenated_df i.e. dframe \n",
    "    \"\"\"\n",
    "    concatenated_df = pd.concat(processed_dic.values(), axis = 0, ignore_index=True)\n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3330d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_df(df, targetCol):\n",
    "    \"\"\"\n",
    "    Segment df into sliding windows of values.\n",
    "    Input: df i.e. concatenated mega df containing all feature cols \n",
    "           for all sample points from all trials of dance moves by all subjects \n",
    "    Input: targetCol i.e. labels col for dance moves \n",
    "    Returns: 3D Numpy Array representing Windows of values and the corresponding labels \n",
    "    \"\"\"\n",
    "    global FEATURE_COLS_LEN, SEGMENT_SIZE, OVERLAP, FEATURE_COLS\n",
    "    \n",
    "    segments = []\n",
    "    labels = []\n",
    "    # In each iteration, the row jumps by the overlap size\n",
    "    # grab all rows of feature column values corresponding to length of segment \n",
    "    # grab corresponding mode of targetCol\n",
    "    for row in range(0, len(df) - SEGMENT_SIZE, OVERLAP):\n",
    "        window = []\n",
    "        for col in FEATURE_COLS:\n",
    "            window.append(df[col].values[row:row+SEGMENT_SIZE])\n",
    "            \n",
    "        segments.append(window)\n",
    "        label = stats.mode(df[targetCol][row:row+SEGMENT_SIZE])[0][0]\n",
    "        labels.append(label)\n",
    "        \n",
    "    reshaped_segments = np.asarray(segments,dtype =np.float32).reshape(-1,SEGMENT_SIZE,FEATURE_COLS_LEN)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    # reshaped_segments will be x and labels will be y \n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a18ff7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputVector(reshapedSegments):\n",
    "    \"\"\"\n",
    "    Get the input vector to be fed into nn.\n",
    "    Input: reshapedSegments after segmentation of df \n",
    "    Return: Input vector of shape n windows * (20*2*12)\n",
    "    Note: num of windows, n = (len(df) / overlap) - 1, if you take first window as w1, else it will be (len(df) / overlap) - 2\n",
    "    \"\"\"\n",
    "    global SAMPLING_FREQ, WINDOW_SIZE, FEATURE_COLS_LEN\n",
    "    \n",
    "    num_of_input_features = SAMPLING_FREQ * WINDOW_SIZE * FEATURE_COLS_LEN\n",
    "    inputVector = reshapedSegments.reshape(reshapedSegments.shape[0], num_of_input_features)\n",
    "    \n",
    "    return inputVector.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23f7f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUp(dframe,sub,trialNum,dance):\n",
    "    \"\"\"\n",
    "    Lookup a particular subject's df based on trialNum and dance in a dataframe.\n",
    "    Inputs: dataframe, str(subject), str(trialNumber) and str(danceMove)\n",
    "    Returns: the dataframe under consideration.\n",
    "    \"\"\"\n",
    "    df_considered = dframe[(dframe[\"subject\"] == sub) & (dframe[\"trialNum\"] == trialNum) & (dframe[\"dance\"] == dance)]\n",
    "    return df_considered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c433e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mapping(danceArray):\n",
    "    \"\"\"\n",
    "    Get two dicts. One with dance mapped to number and the other with number mapped to dance.\n",
    "    Input: Unique dance moves in 1d array\n",
    "    Returns: ({dance: num}, {num: dance})\n",
    "    \"\"\"\n",
    "    map_dance_to_num = {}\n",
    "    map_num_to_dance = {}\n",
    "    for i, move in enumerate(danceArray): \n",
    "        map_num_to_dance[i] = move\n",
    "        map_dance_to_num[move] = i\n",
    "    return (map_dance_to_num, map_num_to_dance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b52414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.grid(False)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e28f32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "# test_dic = generate_final_dataset(gen_rawData(load_data_paths(TEST_FILEPATH)))\n",
    "# data_test, lbl_test = segment_df(concatenator(test_dic), \"target\")\n",
    "# test_X = getInputVector(data_test)\n",
    "# test_X.shape\n",
    "# len(test_X)\n",
    "# unique, counts = np.unique(lbl_test, return_counts=True)\n",
    "# dict(zip(unique, counts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
