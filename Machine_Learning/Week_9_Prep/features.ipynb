{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b4ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sn\n",
    "plt.style.use('ggplot')\n",
    "sn.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import medfilt\n",
    "from scipy.fftpack import fft \n",
    "from scipy.fftpack import fftfreq \n",
    "from scipy.fftpack import ifft \n",
    "from numpy.fft import *\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81a47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_FREQ = 20 # Hz \n",
    "WINDOW_SIZE = 1 # sec \n",
    "OVERLAP = 10 # 10 steps forward and 10 steps from prev window \n",
    "SEGMENT_SIZE = SAMPLING_FREQ * WINDOW_SIZE # 20\n",
    "FEATURE_COLS_LEN = 12 \n",
    "FEATURE_COLS = ['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n",
    "                't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n",
    "                't_body_gyro_X','t_body_gyro_Y','t_body_gyro_Z',\n",
    "                't_body_acc_mag','t_grav_acc_mag','t_body_gyro_mag']\n",
    "\n",
    "\n",
    "# NYQ = SAMPLING_FREQ / float(2) # Nyquist frequency \n",
    "CUTOFF = 0.3 \n",
    "MAXFREQ = 10 \n",
    "\n",
    "SENSOR_COLS = [\"acc_X\", \"acc_Y\", \"acc_Z\", \"gyro_X\", \"gyro_Y\", \"gyro_Z\", \"yaw\", \"pitch\", \"roll\"]\n",
    "COLS_USED = [\"acc_X\", \"acc_Y\", \"acc_Z\", \"gyro_X\", \"gyro_Y\", \"gyro_Z\"]\n",
    "ADDITIONAL_COLS = [\"subject\", \"trialNum\", \"dance\"]\n",
    "RAW_COLS = [\"acc_X\", \"acc_Y\", \"acc_Z\", \"gyro_X\", \"gyro_Y\", \"gyro_Z\",\"subject\", \"trialNum\", \"dance\"]\n",
    "\n",
    "DANCE_TO_NUM_MAP = {'dab': 0, 'jamesbond': 1, 'mermaid': 2}\n",
    "# NUM_TO_DANCE_MAP = {0: 'dab', 1: 'jamesbond', 2: 'mermaid'}\n",
    "\n",
    "TRAIN_FILEPATH = \"./capstone_data/train/*.csv\"\n",
    "TEST_FILEPATH = \"./capstone_data/test/*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a3216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_paths(location):\n",
    "    \"\"\"\n",
    "    Gets file path to each csv data file.\n",
    "    Input: filepath to csv files i.e. string\n",
    "    Return: 1D array of filepath to each csv which contains sensor data for each trial by a subject for a dance move \n",
    "    \"\"\"\n",
    "    data_paths = []\n",
    "    for name in glob.glob(location):\n",
    "        data_paths.append(name)\n",
    "    return data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d38869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliseData(dframe):\n",
    "    \"\"\"\n",
    "    Normalize features for data set (values between 0 and 1). Columns rounded to 4dp after normalisation.\n",
    "    Input: raw sensor dframe \n",
    "    No return value\n",
    "    \"\"\"\n",
    "    \n",
    "    global COLS_USED\n",
    "    \n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    for col in COLS_USED:\n",
    "        dframe[col] = dframe[col] / dframe[col].max()\n",
    "        dframe[col] = dframe[col].round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e409050e",
   "metadata": {},
   "source": [
    " - Each filepath corresponds to a diff csv file \n",
    " - Each file has 20samples per sec * 60s = 1200 values & each subject does a dance move for 3 trials\n",
    " - Hence 3600 values per subject for a dance move\n",
    " - Thus for n dance moves, each subject has 3600 * n values\n",
    " - With k subjects, the dataset will have k * 3600 * n values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f81b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rawData(given_filepaths):\n",
    "    \"\"\"\n",
    "    Generate training and test dataframes from raw sensor data packaged into dict.\n",
    "    Input: given_filepaths i.e. filepaths 1D array\n",
    "    Return: dictionary of raw dfs, with key being {subjectName}_{dance}_{trialNum}\n",
    "    \"\"\"\n",
    "    frames = {}\n",
    "    for filepath in given_filepaths:\n",
    "        _, s, subjectName, ext = filepath.split(\"_\")\n",
    "        _, _, dance = s.split(\"/\")\n",
    "        trialNum, _ = ext.split(\".\")\n",
    "        raw_df = pd.read_csv(filepath, names=SENSOR_COLS, index_col=None)\n",
    "        raw_df.dropna(inplace= True)\n",
    "        raw_df.drop([\"yaw\",\"pitch\",\"roll\"], axis=1, inplace=True)\n",
    "        raw_df.reset_index(drop=True,inplace=True)\n",
    "        for col in raw_df.columns: \n",
    "            raw_df[col] = raw_df[col].div(100).round(6) # received sensor data was scaled by 100 \n",
    "        raw_df[\"subject\"] = subjectName\n",
    "        raw_df[\"trialNum\"] = int(trialNum)\n",
    "        raw_df[\"dance\"] = dance\n",
    "        frames[f\"{subjectName}_{dance}_{trialNum}\"] = raw_df\n",
    "    return frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2b6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(signal):\n",
    "    \"\"\"\n",
    "    Applies 3rd order median filter for each signal i.e. Each axial column in dataset.\n",
    "    Input: 1D Numpy array i.e. one column\n",
    "    Return: 3rd order median-filtered signal i.e 1D Numpy array\n",
    "    \"\"\"\n",
    "    array = np.array(signal)   \n",
    "    med_filtered = medfilt(array, kernel_size=3) \n",
    "    return  med_filtered  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4f2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_3_signals(x,y,z): \n",
    "    \"\"\"\n",
    "    Finding Euclidian magnitude of 3-axial signal values of each row i.e. each sample point.\n",
    "    Inputs: x, y , z columns (1D Numpy arrays)\n",
    "    Return: Euclidian magnitude of each 3-axial signals\n",
    "    \"\"\"\n",
    "    return [math.sqrt((x[i]**2+y[i]**2+z[i]**2)) for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b45f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_domain_feature_per_signal(t_signal):\n",
    "    \"\"\"\n",
    "    For each time-domain signal, i.e. accx,y,z and gyrox,y,z, split into their respective time-domain components.\n",
    "    Input: t_signal i.e. 1D Numpy array (time domain signal - each column)\n",
    "    Returns: (total_component, t_DC_component , t_body_component, t_noise)\n",
    "    \"\"\"\n",
    "    \n",
    "    global CUTOFF, MAXFREQ, SAMPLING_FREQ\n",
    "    \n",
    "    t_signal = np.array(t_signal)\n",
    "    t_signal_length = len(t_signal) \n",
    "#     print(\"number of sample points in t_signal\", t_signal_length) \n",
    "    \n",
    "    # 1D numpy array containing complex values\n",
    "    f_signal = fft(t_signal) \n",
    "    \n",
    "    # generate frequencies associated to f_signal complex values\n",
    "    # frequency values between [-10hz:+10hz]\n",
    "    freqs = np.array(sp.fftpack.fftfreq(t_signal_length, d = 1/float(SAMPLING_FREQ))) \n",
    "#     print(\"printing max freq under t_dom_feat_per_sig\", freqs.max())\n",
    "#     print(\"printing min freq under t_dom_feat_per_sig\", freqs.min())\n",
    "    f_DC_signal = [] # DC_component in freq domain\n",
    "    f_body_signal = [] # body component in freq domain \n",
    "    f_noise_signal = [] # noise in freq domain\n",
    "    \n",
    "    # iterate over all available frequencies\n",
    "    for i, freq in enumerate(freqs):\n",
    "          \n",
    "        # selecting the f_signal value associated to freq\n",
    "        value = f_signal[i]\n",
    "        \n",
    "        # Selecting DC_component values \n",
    "        if abs(freq) > CUTOFF:\n",
    "            f_DC_signal.append(float(0))                                       \n",
    "        else: \n",
    "            f_DC_signal.append(value) \n",
    "    \n",
    "        # Selecting noise component values \n",
    "        if (abs(freq) <= MAXFREQ):\n",
    "            f_noise_signal.append(float(0))  \n",
    "        else:\n",
    "            f_noise_signal.append(value) \n",
    "\n",
    "        # Selecting body_component values \n",
    "        if (abs(freq) <= CUTOFF or abs(freq) > MAXFREQ):\n",
    "            f_body_signal.append(float(0))\n",
    "        else:\n",
    "            f_body_signal.append(value) \n",
    "    \n",
    "   \n",
    "    t_DC_component = ifft(np.array(f_DC_signal)).real\n",
    "    t_body_component = ifft(np.array(f_body_signal)).real\n",
    "    t_noise = ifft(np.array(f_noise_signal)).real\n",
    "    \n",
    "    # extracting the total component(filtered from noise)\n",
    "    total_component = t_signal - t_noise  \n",
    "                                     \n",
    "    return (total_component,t_DC_component,t_body_component,t_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ecbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_domain_feature_gen(df):\n",
    "    \"\"\"\n",
    "    Add time domain features to df which contains normalised sensor values.\n",
    "    Input : raw df i.e. concatenated complete df with all sensor values after being normalised\n",
    "    Return : df with 12 cols appended from feature extraction \n",
    "    \"\"\"    \n",
    "\n",
    "    global COLS_USED\n",
    "    \n",
    "    # iterate through all six axial signals \n",
    "    for column in COLS_USED:\n",
    "        t_signal = np.array(df[column])\n",
    "        medfiltered_sig = filter_signal(t_signal)\n",
    "        \n",
    "        if 'acc' in column: \n",
    "            _,grav_acc,body_acc,_ = t_domain_feature_per_signal(medfiltered_sig) \n",
    "            df['t_body_'+ column] = body_acc\n",
    "            df['t_grav_'+ column] = grav_acc \n",
    "            \n",
    "        elif 'gyro' in column: \n",
    "            _,_,body_gyro,_ = t_domain_feature_per_signal(medfiltered_sig)\n",
    "            df['t_body_gyro_'+ column[-1]] = body_gyro\n",
    "    \n",
    "    \n",
    "    # all 9 axial signals generated above are reordered to facilitate find magnitude\n",
    "    new_columns_ordered = ['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n",
    "                          't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n",
    "                          't_body_gyro_X','t_body_gyro_Y','t_body_gyro_Z']\n",
    "    \n",
    "    \n",
    "    # Calculating magnitude by iterating over each 3-axial signal\n",
    "    for i in range(0,9,3): \n",
    "        mag_col_name = new_columns_ordered[i][:-1]+'mag'\n",
    "        x_col = np.array(df[new_columns_ordered[i]])   # copy X_component\n",
    "        y_col = np.array(df[new_columns_ordered[i+1]]) # copy Y_component\n",
    "        z_col = np.array(df[new_columns_ordered[i+2]]) # copy Z_component\n",
    "        \n",
    "        mag_signal = mag_3_signals(x_col,y_col,z_col) # calculate magnitude of each signal[X,Y,Z]\n",
    "        df[mag_col_name] = mag_signal \n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc6e4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenator(raw_dic):\n",
    "    \"\"\"\n",
    "    Concatenate raw dict along the rows to generate raw train and raw test dframes which can be sent for feature gen.\n",
    "    Input: raw_dic\n",
    "    Return: concatenated_df i.e. dframe \n",
    "    \"\"\"\n",
    "    concatenated_df = pd.concat(raw_dic.values(), axis = 0, ignore_index=True)\n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3330d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_df(df, targetCol):\n",
    "    \"\"\"\n",
    "    Segment df into sliding windows of values.\n",
    "    Input: df i.e. concatenated mega df containing all feature cols \n",
    "           for all sample points from all trials of dance moves by all subjects \n",
    "    Input: targetCol i.e. labels col for dance moves \n",
    "    Returns: 3D Numpy Array representing Windows of values and the corresponding labels \n",
    "    \"\"\"\n",
    "    global FEATURE_COLS_LEN, SEGMENT_SIZE, OVERLAP, FEATURE_COLS\n",
    "    \n",
    "    segments = []\n",
    "    labels = []\n",
    "    # In each iteration, the row jumps by the overlap size\n",
    "    # grab all rows of feature column values corresponding to length of segment \n",
    "    # grab corresponding mode of targetCol\n",
    "    for row in range(0, len(df) - SEGMENT_SIZE, OVERLAP):\n",
    "        window = []\n",
    "        for col in FEATURE_COLS: \n",
    "            window.append(df[col][row:row+SEGMENT_SIZE].values)\n",
    "            \n",
    "        segments.append(window)\n",
    "        label = stats.mode(df[targetCol][row:row+SEGMENT_SIZE])[0][0]\n",
    "        labels.append(label)\n",
    "        \n",
    "    reshaped_segments = np.asarray(segments,dtype =np.float32).reshape(-1,SEGMENT_SIZE,FEATURE_COLS_LEN)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    # reshaped_segments will be x and labels will be y \n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a18ff7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputVector(reshapedSegments):\n",
    "    \"\"\"\n",
    "    Get the input vector to be fed into nn.\n",
    "    Input: reshapedSegments after segmentation of df \n",
    "    Return: Input vector of shape n windows * (20*1*12)\n",
    "    Note: num of windows, n = (len(df) / overlap) - 1, if you take first window as w1, else it will be (len(df) / overlap) - 2\n",
    "    \"\"\"\n",
    "    global SAMPLING_FREQ, WINDOW_SIZE, FEATURE_COLS_LEN\n",
    "    \n",
    "    num_of_input_features = SAMPLING_FREQ * WINDOW_SIZE * FEATURE_COLS_LEN\n",
    "    inputVector = reshapedSegments.reshape(reshapedSegments.shape[0], num_of_input_features)\n",
    "    \n",
    "    return inputVector.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23f7f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUp(dframe,sub,trialNum,dance):\n",
    "    \"\"\"\n",
    "    Lookup a particular subject's df based on trialNum and dance in a dataframe.\n",
    "    Inputs: dataframe, str(subject), str(trialNumber) and str(danceMove)\n",
    "    Returns: the dataframe under consideration.\n",
    "    \"\"\"\n",
    "    df_considered = dframe[(dframe[\"subject\"] == sub) & (dframe[\"trialNum\"] == trialNum) & (dframe[\"dance\"] == dance)]\n",
    "    return df_considered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c433e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mapping(danceArray):\n",
    "    \"\"\"\n",
    "    Get two dicts. One with dance mapped to number and the other with number mapped to dance.\n",
    "    Input: Unique dance moves in 1d array\n",
    "    Returns: ({dance: num}, {num: dance})\n",
    "    \"\"\"\n",
    "    map_dance_to_num = {}\n",
    "    map_num_to_dance = {}\n",
    "    for i, move in enumerate(danceArray): \n",
    "        map_num_to_dance[i] = move\n",
    "        map_dance_to_num[move] = i\n",
    "    return (map_dance_to_num, map_num_to_dance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b52414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.grid(False)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e28f32ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training segments shape:  (5398, 20, 12)\n",
      "Testing segments shape:  (1078, 20, 12)\n",
      "Input Training Vector shape:  (5398, 240)\n",
      "Input Testing Vector shape:  (1078, 240)\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "raw_test_df = concatenator(gen_rawData(load_data_paths(TEST_FILEPATH)))\n",
    "raw_train_df = concatenator(gen_rawData(load_data_paths(TRAIN_FILEPATH)))\n",
    "normaliseData(raw_test_df)\n",
    "normaliseData(raw_train_df)\n",
    "feature_test_df = time_domain_feature_gen(raw_test_df)\n",
    "feature_train_df = time_domain_feature_gen(raw_train_df)\n",
    "feature_train_df[\"target\"] = feature_train_df[\"dance\"].map(DANCE_TO_NUM_MAP)\n",
    "feature_test_df = time_domain_feature_gen(raw_test_df)\n",
    "feature_test_df[\"target\"] = feature_test_df[\"dance\"].map(DANCE_TO_NUM_MAP)\n",
    "segment_train_df = feature_train_df.drop(RAW_COLS, axis = 1)\n",
    "segment_test_df = feature_test_df.drop(RAW_COLS, axis=1)\n",
    "train_segs, lbl_train = segment_df(segment_train_df,\"target\")\n",
    "test_segs, lbl_test = segment_df(segment_test_df, \"target\")\n",
    "training_X = getInputVector(train_segs)\n",
    "testing_X = getInputVector(test_segs)\n",
    "print(\"Training segments shape: \", train_segs.shape)\n",
    "print(\"Testing segments shape: \", test_segs.shape)\n",
    "print(\"Input Training Vector shape: \", training_X.shape)\n",
    "print(\"Input Testing Vector shape: \", testing_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00c0d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_test_df[\"acc_X\"][0:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
