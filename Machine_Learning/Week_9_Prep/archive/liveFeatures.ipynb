{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ea48d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import medfilt\n",
    "from scipy.fftpack import fft \n",
    "from scipy.fftpack import fftfreq \n",
    "from scipy.fftpack import ifft \n",
    "from numpy.fft import *\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a5991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_FREQ = 20 # Hz \n",
    "WINDOW_SIZE =  # sec \n",
    "OVERLAP = 10 # 10 steps forward and 10 steps from prev window \n",
    "SEGMENT_SIZE = SAMPLING_FREQ * WINDOW_SIZE # 20\n",
    "FEATURE_COLS_LEN = 12 \n",
    "FEATURE_COLS = ['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n",
    "                't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n",
    "                't_body_gyro_X','t_body_gyro_Y','t_body_gyro_Z',\n",
    "                't_body_acc_mag','t_grav_acc_mag','t_body_gyro_mag']\n",
    "\n",
    "TRAIN_MAX = {'acc_X': 1.27,\n",
    "             'acc_Y': 1.27,\n",
    "             'acc_Z': 1.27,\n",
    "             'gyro_X': 276.28,\n",
    "             'gyro_Y': 289.32,\n",
    "             'gyro_Z': 271.8\n",
    "            }\n",
    "\n",
    "CUTOFF = 0.3 \n",
    "MAXFREQ = 10 \n",
    "\n",
    "SENSOR_COLS = [\"acc_X\", \"acc_Y\", \"acc_Z\", \"gyro_X\", \"gyro_Y\", \"gyro_Z\"]\n",
    "SENSOR_COLS_LEN = 6\n",
    "\n",
    "CUMULATIVE_DATA = np.zeros((1,SENSOR_COLS_LEN), dtype=float, order='C') # holds rows of live sensor data sent \n",
    "CUMULATIVE_DATA = np.delete(CUMULATIVE_DATA, 0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e7dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentator():\n",
    "    \"\"\"\n",
    "    Extract segments using fixed-width sliding windows of size 1s. \n",
    "    Return: 3D Numpy array of size : n segments * 6 axial cols * 20 rows \n",
    "    \"\"\"\n",
    "    global CUMULATIVE_DATA, OVERLAP, SEGMENT_SIZE,SENSOR_COLS_LEN \n",
    "    \n",
    "    # loop through the 2d array of nrows * 6\n",
    "    # capture each column ==> len of each col = 20 and there should 6 cols ==> this will be the first segment \n",
    "    # segments will be a n segments * 6 col * 20 values \n",
    "    \n",
    "    segments = []\n",
    "    for row in range(0, len(CUMULATIVE_DATA)-(SEGMENT_SIZE-1), OVERLAP): \n",
    "#         print(f\"Sampling row:{row} to row:{row+SEGMENT_SIZE}\")\n",
    "        windows = []\n",
    "        for col in range(0,SENSOR_COLS_LEN):\n",
    "            windows.append(CUMULATIVE_DATA[row:row+SEGMENT_SIZE,col])\n",
    "#         print(\"Shape of Window: \", np.asarray(windows).shape)\n",
    "        segments.append(windows)\n",
    "#     print(\"Shape of segments : \", np.asarray(segments).shape)\n",
    "    CUMULATIVE_DATA = np.delete(CUMULATIVE_DATA, np.s_[0:OVERLAP], axis = 0) \n",
    "    reshaped_segments = np.asarray(segments,dtype =np.float32).reshape(-1,SEGMENT_SIZE,SENSOR_COLS_LEN)\n",
    "    return reshaped_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a60efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliseData(dframe):\n",
    "    \"\"\"\n",
    "    Normalize axial features (values between 0 and 1). Columns rounded to 4dp after normalisation.\n",
    "    Input: raw sensor data dframe \n",
    "    No return value\n",
    "    \"\"\"\n",
    "    \n",
    "    global SENSOR_COLS, TRA\n",
    "    \n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    for col in SENSOR_COLS:\n",
    "        dframe[col] = dframe[col].div(100).round(6) # received sensor data were scaled by 100\n",
    "        dframe[col] = dframe[col] / TRAIN_MAX[col]\n",
    "        dframe[col] = dframe[col].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a674cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(signal):\n",
    "    \"\"\"\n",
    "    Applies 3rd order median filter for each signal i.e. Each axial column in dataset.\n",
    "    Input: 1D Numpy array i.e. one column\n",
    "    Return: 3rd order median-filtered signal i.e 1D Numpy array\n",
    "    \"\"\"\n",
    "    array = np.array(signal)   \n",
    "    med_filtered = medfilt(array, kernel_size=3) \n",
    "    return  med_filtered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "790f4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_3_signals(x,y,z): \n",
    "    \"\"\"\n",
    "    Finding Euclidian magnitude of 3-axial signal values of each row i.e. each sample point.\n",
    "    Inputs: x, y , z columns (1D Numpy arrays)\n",
    "    Return: Euclidian magnitude of each 3-axial signals\n",
    "    \"\"\"\n",
    "    return [math.sqrt((x[i]**2+y[i]**2+z[i]**2)) for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d438690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_domain_feature_per_signal(t_signal):\n",
    "    \"\"\"\n",
    "    For each time-domain signal, i.e. accx,y,z and gyrox,y,z, split into their respective time-domain components.\n",
    "    Input: t_signal i.e. 1D Numpy array (time domain signal - each column)\n",
    "    Returns: (total_component, t_DC_component , t_body_component, t_noise)\n",
    "    \"\"\"\n",
    "    \n",
    "    global CUTOFF, MAXFREQ, SAMPLING_FREQ\n",
    "    \n",
    "    t_signal = np.array(t_signal)\n",
    "    t_signal_length = len(t_signal) \n",
    "#     print(\"number of sample points in t_signal\", t_signal_length) \n",
    "    \n",
    "    # 1D numpy array containing complex values\n",
    "    f_signal = fft(t_signal) \n",
    "    \n",
    "    # generate frequencies associated to f_signal complex values\n",
    "    # frequency values between [-10hz:+10hz]\n",
    "    freqs = np.array(sp.fftpack.fftfreq(t_signal_length, d = 1/float(SAMPLING_FREQ))) \n",
    "#     print(\"printing max freq under t_dom_feat_per_sig\", freqs.max())\n",
    "#     print(\"printing min freq under t_dom_feat_per_sig\", freqs.min())\n",
    "    f_DC_signal = [] # DC_component in freq domain\n",
    "    f_body_signal = [] # body component in freq domain \n",
    "    f_noise_signal = [] # noise in freq domain\n",
    "    \n",
    "    # iterate over all available frequencies\n",
    "    for i, freq in enumerate(freqs):\n",
    "          \n",
    "        # selecting the f_signal value associated to freq\n",
    "        value = f_signal[i]\n",
    "        \n",
    "        # Selecting DC_component values \n",
    "        if abs(freq) > CUTOFF:\n",
    "            f_DC_signal.append(float(0))                                       \n",
    "        else: \n",
    "            f_DC_signal.append(value) \n",
    "    \n",
    "        # Selecting noise component values \n",
    "        if (abs(freq) <= MAXFREQ):\n",
    "            f_noise_signal.append(float(0))  \n",
    "        else:\n",
    "            f_noise_signal.append(value) \n",
    "\n",
    "        # Selecting body_component values \n",
    "        if (abs(freq) <= CUTOFF or abs(freq) > MAXFREQ):\n",
    "            f_body_signal.append(float(0))\n",
    "        else:\n",
    "            f_body_signal.append(value) \n",
    "    \n",
    "   \n",
    "    t_DC_component = ifft(np.array(f_DC_signal)).real\n",
    "    t_body_component = ifft(np.array(f_body_signal)).real\n",
    "    t_noise = ifft(np.array(f_noise_signal)).real\n",
    "    \n",
    "    # extracting the total component(filtered from noise)\n",
    "    total_component = t_signal - t_noise  \n",
    "                                     \n",
    "    return (total_component,t_DC_component,t_body_component,t_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c449f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_domain_feature_gen(df):\n",
    "    \"\"\"\n",
    "    Add time domain features to df which contains normalised sensor values.\n",
    "    Input : raw df i.e. segmented df with all 6 axial sensor values after being normalised\n",
    "    Return : df with 12 cols appended from feature extraction \n",
    "    \"\"\"    \n",
    "    \n",
    "    global SENSOR_COLS\n",
    "    \n",
    "    # iterate through all six axial signals \n",
    "    for column in SENSOR_COLS:\n",
    "        t_signal = np.array(df[column])\n",
    "        medfiltered_sig = filter_signal(t_signal)\n",
    "        \n",
    "        if 'acc' in column: \n",
    "            _,grav_acc,body_acc,_ = t_domain_feature_per_signal(medfiltered_sig) \n",
    "            df['t_body_'+ column] = body_acc\n",
    "            df['t_grav_'+ column] = grav_acc \n",
    "            \n",
    "        elif 'gyro' in column: \n",
    "            _,_,body_gyro,_ = t_domain_feature_per_signal(medfiltered_sig)\n",
    "            df['t_body_gyro_'+ column[-1]] = body_gyro\n",
    "    \n",
    "    \n",
    "    # all 9 axial signals generated above are reordered to facilitate find magnitude\n",
    "    new_columns_ordered = ['t_body_acc_X','t_body_acc_Y','t_body_acc_Z',\n",
    "                          't_grav_acc_X','t_grav_acc_Y','t_grav_acc_Z',\n",
    "                          't_body_gyro_X','t_body_gyro_Y','t_body_gyro_Z']\n",
    "    \n",
    "    \n",
    "    # Calculating magnitude by iterating over each 3-axial signal\n",
    "    for i in range(0,9,3): \n",
    "        mag_col_name = new_columns_ordered[i][:-1]+'mag'\n",
    "        x_col = np.array(df[new_columns_ordered[i]])   # copy X_component\n",
    "        y_col = np.array(df[new_columns_ordered[i+1]]) # copy Y_component\n",
    "        z_col = np.array(df[new_columns_ordered[i+2]]) # copy Z_component\n",
    "        \n",
    "        mag_signal = mag_3_signals(x_col,y_col,z_col) # calculate magnitude of each signal[X,Y,Z]\n",
    "        df[mag_col_name] = mag_signal \n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56912e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfinalSegs(segs):\n",
    "    \"\"\"\n",
    "    Extract features for each window selected and convert into segments array\n",
    "    Input: 3D Numpy segments array obtained after segmentation\n",
    "    Return: 3D Numpy array with features extracted and raw cols removed\n",
    "    \"\"\"\n",
    "    arr = np.asarray(segs)\n",
    "    final_segs = []\n",
    "    for r in range(0, arr.shape[0]):\n",
    "        df = pd.DataFrame(arr[r], index=None, columns=SENSOR_COLS)\n",
    "        normaliseData(df)\n",
    "        df_feat = time_domain_feature_gen(df)\n",
    "        final_segs.append(df_feat.drop(SENSOR_COLS, axis = 1).values)\n",
    "    return np.asarray(final_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "576135be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputVector(finalSegs):\n",
    "    \"\"\"\n",
    "    Get the input vector to be fed into nn.\n",
    "    Input: finalSegs after feature extraction \n",
    "    Return: Input vector of shape n windows * (20*1*12)\n",
    "    Note: num of windows, n = (len(df) / overlap) - 1, if you take first window as w1, else it will be (len(df) / overlap) - 2\n",
    "    \"\"\"\n",
    "    global SAMPLING_FREQ, WINDOW_SIZE, FEATURE_COLS_LEN\n",
    "    \n",
    "    num_of_input_features = SAMPLING_FREQ * WINDOW_SIZE * FEATURE_COLS_LEN\n",
    "    inputVector = finalSegs.reshape(finalSegs.shape[0], num_of_input_features)\n",
    "    \n",
    "    return inputVector.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dacce1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetCumData():\n",
    "    \"\"\"\n",
    "    Function to be called before the start of dance move execution. Resets CUMULATIVE_DATA to empty numpy arr. \n",
    "    \"\"\"\n",
    "    global CUMULATIVE_DATA, SENSOR_COLS_LEN\n",
    "    \n",
    "    # holds rows of sensor data with 6 axial cols\n",
    "    CUMULATIVE_DATA = np.zeros((1,SENSOR_COLS_LEN), dtype=float, order='C')  \n",
    "    CUMULATIVE_DATA = np.delete(CUMULATIVE_DATA, 0,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86839db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append(data):\n",
    "    \"\"\"\n",
    "    Each row of live sensor data of 6 axial values, will be appended to a global 2D Numpy array. \n",
    "    From the global 2D Numpy array, a window of readings will be selected \n",
    "    to form an input vector of shape n x 240 to be fed into the nn.\n",
    "    Input: data, i.e. 2D Numpy array of shape (20,6) is preferred \n",
    "    Returns: n x (20 * 12) Numpy array to be fed as input to nn model, where n is the number of windows\n",
    "    \"\"\"\n",
    "    global CUMULATIVE_DATA , SENSOR_COLS_LEN, SEGMENT_SIZE \n",
    "    arr = np.array(data)\n",
    "    \n",
    "    # padding \n",
    "    if len(arr) < SEGMENT_SIZE:\n",
    "        leftover = SEGMENT_SIZE - len(arr)\n",
    "        padding = np.zeros((leftover, SENSOR_COLS_LEN),dtype=float, order='C')\n",
    "        arr = np.concatenate((arr,padding))\n",
    "        \n",
    "    CUMULATIVE_DATA = np.concatenate((CUMULATIVE_DATA, arr))\n",
    "#     print(\"GLOBAL ARRAY SHAPE BEFORE SEGMENTATION : \", CUMULATIVE_DATA.shape)\n",
    "    segs = segmentator()\n",
    "#     print(\"GLOBAL ARRAY SHAPE AFTER SEGMENTATION : \", CUMULATIVE_DATA.shape)\n",
    "    fin_segs = getfinalSegs(segs)\n",
    "    iv = getInputVector(fin_segs)\n",
    "    \n",
    "    return iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e62d34a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vector shape: (1, 240)\n"
     ]
    }
   ],
   "source": [
    "# # for testing \n",
    "# resetCumData()\n",
    "# df = pd.read_csv(\"./capstone_data/test/dab_sean_1.csv\", index_col=None, header = None )\n",
    "# iv = append(np.asarray(df.values[0:20, 0:6]))\n",
    "# print(\"input vector shape:\", iv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4515e334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vector shape: (2, 240)\n"
     ]
    }
   ],
   "source": [
    "# iv = append(np.asarray(df.values[20:40, 0:6]))\n",
    "# print(\"input vector shape:\", iv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f12a04cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vector shape: (3, 240)\n"
     ]
    }
   ],
   "source": [
    "# iv = append(np.asarray(df.values[40:60, 0:6]))\n",
    "# print(\"input vector shape:\", iv.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
